{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prototype Dataset\n",
    "This file generates the path-to-path dataset to train a prototype transformer\n",
    "\n",
    "The input output sequence of a logo should consist of 269 Parameters\n",
    "- DeepSVG Embedding (256)\n",
    "- Type \"EOS\" (1) (open for discussion, but it makes the most sense in the predicting process ~Corni)\n",
    "- Type (6)\n",
    "- Param (6)\n",
    "\n",
    "Input Sequence\n",
    "- In the input sequence, the last 13 Parameters are set to zero\n",
    "- In a final model, these parameters are aimed to be left out (as context vector isn't based on that)\n",
    "\n",
    "Output Sequence\n",
    "- The Output sequence consists of the selected paths represented by their DeepSVG Embedding\n",
    "- The Animation is represented through the type and the parameters.\n",
    "- Each output sequence ends with an EOS Token, where the EOS-type in the one-hot-encoded part is set to 1."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f87acc6b5c53311e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import DeepSVG Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc106e338f0e309d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/embeddings/path_embedding.pkl\", \"rb\") as f:\n",
    "    deepsvg_embedding = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68694a80615a4275",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## duplicate for further use\n",
    "embeddings = deepsvg_embedding.copy() #for output sequences\n",
    "input_sequences = deepsvg_embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb59123a29038005",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embeddings['animation_id'] = embeddings['animation_id'].astype(int)\n",
    "embeddings.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da861ad9f01a944",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Input Sequence (Embedded Logo Paths)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6e48324318b5982"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_sequences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c92aaa24f3294fe",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logo Dataset\n",
    "Most logos have only a few paths\n",
    "Some logos have over 100 paths to animate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8cd22cb0cffcf0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_sequences['filename'].value_counts().hist(bins=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b9597e294788436",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_sequences['filename'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d06ebe4eedf0db63",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Count occurrences\n",
    "logos = input_sequences.groupby('filename').size().reset_index(name='count')\n",
    "\n",
    "# To stratify later, categorize the sizes\n",
    "\n",
    "# Percentiles by Data\n",
    "quantiles = [0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    "percentiles = logos['count'].quantile(quantiles)\n",
    "print(percentiles)\n",
    "\n",
    "# Percentiles by Min / Max\n",
    "quantiles2 = [(i+1)/len(quantiles) for i, _ in enumerate(quantiles)]\n",
    "percentiles_mock = [x * (logos['count'].max()-logos['count'].min()) + logos['count'].min() for x in quantiles]\n",
    "print(percentiles_mock)\n",
    "\n",
    "# Mix with harmonic mean that emphasizes small values\n",
    "def harmonic_mean(a, b):\n",
    "    if a == 0 or b == 0:\n",
    "        raise ValueError(\"Harmonic mean is undefined when one or both values are zero.\")\n",
    "    return 2 / ((1 / a) + (1 / b))\n",
    "\n",
    "percentiles_mix = [harmonic_mean(percentile,percentiles_mock[i]) for i, percentile in enumerate(percentiles)]\n",
    "print(percentiles_mix)\n",
    "\n",
    "# Function to categorize based on quantiles\n",
    "def categorize_count(count):\n",
    "    for i, percentile in enumerate(percentiles_mix):\n",
    "        if count <= percentile:\n",
    "            return f\"Quantile {i}\"\n",
    "    return f\"Quantile {len(quantiles)}\"\n",
    "\n",
    "# Apply the categorization function to create a new column\n",
    "logos['count_category'] = logos['count'].apply(categorize_count)\n",
    "logos['count_category'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d582414bf00ab129",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "percentiles"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a527ad1eb4ef0b4d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into training and testing sets, stratifying on 'count_category'\n",
    "X_train, X_test = train_test_split(logos, test_size=0.2, stratify=logos['count_category'], random_state=42)\n",
    "\n",
    "# Print the distribution of 'count_category' in the training and testing sets\n",
    "train_counts = X_train['count_category'].value_counts()\n",
    "test_counts = X_test['count_category'].value_counts()\n",
    "\n",
    "print(\"Training set distribution:\")\n",
    "print(train_counts)\n",
    "\n",
    "print(\"\\nTesting set distribution:\")\n",
    "print(test_counts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d3983833dc6366e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train['count'].hist(bins=50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36a5d435c3bcd9ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_test['count'].hist(bins=50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da0b877551cca13",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Old Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a75939346578e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file\n",
    "with open(\"data/surrogate_model/animation_label.pkl\", \"rb\") as f:\n",
    "    imported_pickle = pickle.load(f)\n",
    "\n",
    "# Create a DataFrame from the imported data\n",
    "filtered_data = pd.DataFrame(imported_pickle, columns=[\"file\", \"animation_id\", \"model_output\", \"label\"])\n",
    "\n",
    "# Define the mapping for ratings\n",
    "mapping_dict = {\"Very Good\": 6, \"Good\": 5, \"Okay\": 4, \"Bad\": 3, \"Very Bad\": 2, \"no_rating\": 1}\n",
    "\n",
    "# Replace the 'label' column with the corresponding ratings using .map\n",
    "filtered_data['rating'] = filtered_data['label'].map(mapping_dict)\n",
    "\n",
    "# Extract unique logos by splitting 'file' with \"_animation\" and using .str.get(0)\n",
    "logos = filtered_data['file'].str.split('_animation').str.get(0).unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbf07bef2aec2144",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#example\n",
    "filtered_data[filtered_data[\"file\"].str.contains(\"logo_5_\")]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "130243845ed47e58",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some Statistics about the Animations we have here\n",
    "Result: Many animations with only one animated path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a27f707d3a85a731"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = filtered_data.groupby('file').count()\n",
    "grouped = grouped[['animation_id']]\n",
    "print(f\"{grouped.size} Animations initially\")\n",
    "histogram_table = grouped['animation_id'].value_counts().reset_index()\n",
    "histogram_table.columns = ['Animation Length', 'Count']\n",
    "histogram_table = histogram_table.sort_values(by='Animation Length')\n",
    "print(histogram_table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9ff5a562cb6b276",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = filtered_data.groupby('label').count()\n",
    "grouped = grouped[['file']].reset_index()\n",
    "grouped.columns = ['Rating', 'Count']\n",
    "grouped['Percentage'] = (grouped['Count'] / grouped['Count'].sum()) * 100\n",
    "grouped"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "860151ed1d201f65",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Investigate overall rating of animations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32e263ddaf7b9683"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data['average_rating'] = filtered_data.groupby('file')['rating'].transform('mean')\n",
    "filtered_data['average_rating'].hist(bins=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbd67fe9b288f9ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# example\n",
    "filtered_data[filtered_data[\"file\"].str.contains(\"logo_5_\")]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c21c5337932e58",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now pick good Animations only\n",
    "Pick the following animations\n",
    "- Best per logo (include as many different logos as possible)\n",
    "- Add all GOOD animations (additionally add as many animations as possible) TODO: Implement later"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ca51f1073850a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data['include'] = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5419a3d2a1cee39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# use all animations with an average rating over 3\n",
    "minimum_rating = 3\n",
    "temp = filtered_data['average_rating'] > minimum_rating\n",
    "filtered_data.loc[temp, 'include'] = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de9be0678e5523f9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"{filtered_data['include'].mean() * 100}% of the data is left out\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23571e53d0ce3431",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# go through each logo to find the best animation\n",
    "for logo in logos:\n",
    "    # make a data frame that contains all the animations of one logo\n",
    "    temp = filtered_data[filtered_data[\"file\"].str.contains(logo)]\n",
    "\n",
    "    best_logo = temp[temp['average_rating'] == temp['average_rating'].max()]\n",
    "    best_logo = best_logo['file'].unique()\n",
    "    \n",
    "    filtered_data.loc[filtered_data['file'].isin(best_logo), 'include'] = 1\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89768ae8bf1f84a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Now {filtered_data['include'].mean() * 100}% of the data is left out\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebb126468661dfd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: No additional animations are selected"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b89401a51abb04eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_output = filtered_data[filtered_data['include'] == 1].copy()\n",
    "best_output.drop(columns=['include'], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d8596ed60930653",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract logo\n",
    "pattern = r'(logo_\\d+)'\n",
    "best_output['filename'] = best_output['file'].str.extract(pattern)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b015491ede981",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some Statistics again\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e427e39220f011c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = best_output.groupby('file').count()\n",
    "grouped = grouped[['animation_id']]\n",
    "print(f\"{grouped.size} Animations left over\")\n",
    "histogram_table = grouped['animation_id'].value_counts().reset_index()\n",
    "histogram_table.columns = ['Animation Length', 'Count']\n",
    "histogram_table = histogram_table.sort_values(by='Animation Length')\n",
    "print(histogram_table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1993ce2ca35e2fb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Output Sequence (Embedded Paths with Animation Vector)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5c4d172ac435313"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge Dataframes\n",
    "output_sequence = pd.merge(best_output, embeddings, on=['filename', 'animation_id'], how='inner')\n",
    "animation_vectors = pd.DataFrame(output_sequence[\"model_output\"].to_list(), columns=[\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"a7\",\"a8\",\"a9\",\"a10\",\"a11\",\"a12\"])\n",
    "output_sequence.drop(['animation_id', 'model_output', 'label', 'rating', 'average_rating', 'filename'], inplace=True, axis=1)\n",
    "output_sequence['a0'] = 0 # EOS Feature in One-hot Encoding\n",
    "output_sequence = pd.merge(output_sequence, animation_vectors, left_index=True, right_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d18f41c9c48fadaa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output_sequence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537e9ae98abafa69",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "827c0b54d1e50143"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
