{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prototype Dataset\n",
    "This file generates the path-to-path dataset to train a prototype transformer\n",
    "\n",
    "The input output sequence of a logo should consist of 270 Parameters\n",
    "- DeepSVG Embedding (256)\n",
    "- a0 Type \"EOS\" (1)\n",
    "- a1 - a6 Type (6)\n",
    "- a7 - a12 Param (6)\n",
    "- a13 time offset from beginning of animation in seconds\n",
    "\n",
    "Input Sequence\n",
    "- In the input sequence, the last 13 Parameters are set to zero\n",
    "- In a final model, these parameters are aimed to be left out (as context vector isn't based on that)\n",
    "\n",
    "Output Sequence\n",
    "- The Output sequence consists of the selected paths represented by their DeepSVG Embedding\n",
    "- The Animation is represented through the type and the parameters.\n",
    "- Each output sequence ends with an EOS Token, where the EOS-type in the one-hot-encoded part is set to 1."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f87acc6b5c53311e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import DeepSVG Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc106e338f0e309d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "with open(\"data/embeddings/path_embedding.pkl\", \"rb\") as f:\n",
    "    deepsvg_embedding = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68694a80615a4275",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## duplicate for further use\n",
    "embeddings = deepsvg_embedding.copy() #for output sequences\n",
    "input_sequences = deepsvg_embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb59123a29038005",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embeddings['animation_id'] = embeddings['animation_id'].astype(int)\n",
    "embeddings.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da861ad9f01a944",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train / Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6e48324318b5982"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logo Dataset Analysis\n",
    "Most logos have only a few paths\n",
    "Some logos have over 100 paths to animate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8cd22cb0cffcf0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Might not execute\n",
    "# input_sequences['filename'].value_counts().hist(bins=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b9597e294788436",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stratify on Number of Paths in Logo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf7e27502d643b9f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Count occurrences\n",
    "logos = input_sequences.groupby('filename').size().reset_index(name='count')\n",
    "\n",
    "# To stratify later, categorize the sizes\n",
    "bins = 20\n",
    "quantiles = [(i+1)/bins for i in range(bins)]\n",
    "print(quantiles)\n",
    "\n",
    "percentiles = logos['count'].quantile(quantiles)\n",
    "print(percentiles)\n",
    "\n",
    "# Function to categorize based on quantiles\n",
    "def categorize_count(count):\n",
    "    for i, percentile in enumerate(percentiles):\n",
    "        if count <= percentile:\n",
    "            return f\"Quantile {i}\"\n",
    "    return f\"Quantile {len(quantiles)}\"\n",
    "\n",
    "# Apply the categorization function to create a new column\n",
    "logos['count_category'] = logos['count'].apply(categorize_count)\n",
    "logos['count_category'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d582414bf00ab129",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train / Test split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7f1f7e2888b5286"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into training and testing sets, stratifying on 'count_category'\n",
    "logos_train, logos_test = train_test_split(logos, test_size=0.2, stratify=logos['count_category'], random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d3983833dc6366e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The distributions of lenghts are now similar. Outliers with a long sequence are in both datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b4c87d7ce1b548"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logos_train['count'].hist(bins=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36a5d435c3bcd9ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logos_test['count'].hist(bins=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da0b877551cca13",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logos_test = logos_test['filename'].unique()\n",
    "logos_train = logos_train['filename'].unique()\n",
    "logos_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bab461f488d5804",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "- One might also stratify over used animation types.\n",
    "- Are there enough good animations in the dataset for logos with lots of paths? -> Manual annotation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81ef715b269a0ba0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Animation Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a75939346578e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file\n",
    "with open(\"data/surrogate_model/animation_label.pkl\", \"rb\") as f:\n",
    "    imported_pickle = pickle.load(f)\n",
    "\n",
    "# Create a DataFrame from the imported data\n",
    "filtered_data = pd.DataFrame(imported_pickle, columns=[\"file\", \"animation_id\", \"model_output\", \"label\"])\n",
    "\n",
    "# Define the mapping for ratings\n",
    "mapping_dict = {\"Very Good\": 6, \"Good\": 5, \"Okay\": 4, \"Bad\": 3, \"Very Bad\": 2, \"no_rating\": 1}\n",
    "\n",
    "# Replace the 'label' column with the corresponding ratings using .map\n",
    "filtered_data['rating'] = filtered_data['label'].map(mapping_dict)\n",
    "\n",
    "# Extract unique logos by splitting 'file' with \"_animation\" and using .str.get(0)\n",
    "#logos_unique = filtered_data['file'].str.split('_animation').str.get(0).unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbf07bef2aec2144",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#example\n",
    "filtered_data[filtered_data[\"file\"].str.contains(\"logo_5_\")]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "130243845ed47e58",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some Statistics about the Animations we have here\n",
    "Result: Many animations with only one animated path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a27f707d3a85a731"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = filtered_data.groupby('file').count()\n",
    "grouped = grouped[['animation_id']]\n",
    "print(f\"{grouped.size} Animations initially\")\n",
    "histogram_table = grouped['animation_id'].value_counts().reset_index()\n",
    "histogram_table.columns = ['Animation Length', 'Count']\n",
    "histogram_table = histogram_table.sort_values(by='Animation Length')\n",
    "print(histogram_table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9ff5a562cb6b276",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = filtered_data.groupby('label').count()\n",
    "grouped = grouped[['file']].reset_index()\n",
    "grouped.columns = ['Rating', 'Count']\n",
    "grouped['Percentage'] = (grouped['Count'] / grouped['Count'].sum()) * 100\n",
    "grouped"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "860151ed1d201f65",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Investigate overall rating of animations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32e263ddaf7b9683"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data['average_rating'] = filtered_data.groupby('file')['rating'].transform('mean')\n",
    "filtered_data['average_rating'].hist(bins=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbd67fe9b288f9ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# example\n",
    "filtered_data[filtered_data[\"file\"].str.contains(\"logo_5_\")]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c21c5337932e58",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now pick good Animations only\n",
    "Pick the following animations\n",
    "- Best per logo (include as many different logos as possible)\n",
    "- Add all GOOD animations (additionally add as many animations as possible) TODO: Implement later"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ca51f1073850a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data['include'] = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5419a3d2a1cee39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# use all animations with an average rating over 3\n",
    "minimum_rating = 3\n",
    "temp = filtered_data['average_rating'] > minimum_rating\n",
    "filtered_data.loc[temp, 'include'] = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de9be0678e5523f9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"{filtered_data['include'].mean() * 100}% of the data is left out\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23571e53d0ce3431",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# go through each logo to find the best animation\n",
    "for logo in logos:\n",
    "    # make a data frame that contains all the animations of one logo\n",
    "    temp = filtered_data[filtered_data[\"file\"].str.contains(logo)]\n",
    "\n",
    "    best_logo = temp[temp['average_rating'] == temp['average_rating'].max()]\n",
    "    best_logo = best_logo['file'].unique()\n",
    "    \n",
    "    filtered_data.loc[filtered_data['file'].isin(best_logo), 'include'] = 1\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89768ae8bf1f84a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Now {filtered_data['include'].mean() * 100}% of the data is left out\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebb126468661dfd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: No additional animations are selected"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b89401a51abb04eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_output = filtered_data[filtered_data['include'] == 1].copy()\n",
    "best_output.drop(columns=['include'], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d8596ed60930653",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract logo\n",
    "pattern = r'(logo_\\d+)'\n",
    "best_output['filename'] = best_output['file'].str.extract(pattern)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b015491ede981",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Numeration to keep order later (corresponds to start-time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7333d519facdacd5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a time_offset column filled with zeros\n",
    "best_output['a13'] = 0.0\n",
    "\n",
    "# Define animation start time offset in seconds from animation start\n",
    "TIME_OFFSET_STEP = 0.25\n",
    "\n",
    "# Initialize a dictionary to store numbering for each file\n",
    "file_counts = {}\n",
    "\n",
    "# Iterate through the \"file\" column and number each unique file\n",
    "for index, row in best_output.iterrows():\n",
    "    filename = row['file']\n",
    "    if filename not in file_counts:\n",
    "        file_counts[filename] = 1\n",
    "    else:\n",
    "        file_counts[filename] += 1\n",
    "    best_output.at[index, 'a13'] = file_counts[filename] * TIME_OFFSET_STEP\n",
    "best_output.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eb50787fb7ba2d1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stat: Animated paths per logo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6810cac385fb0ab0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "used_paths = best_output[[\"filename\", \"animation_id\"]].drop_duplicates(\n",
    "    subset = ['filename', 'animation_id'], keep = 'last').reset_index(drop = True)\n",
    "used_paths.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37720cb3f400d63a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "used_paths.groupby(['filename']).count().hist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bf2b3d098c776df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some Statistics again\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e427e39220f011c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = best_output.groupby('file').count()\n",
    "grouped = grouped[['animation_id']]\n",
    "print(f\"{grouped.size} Animations left over\")\n",
    "histogram_table = grouped['animation_id'].value_counts().reset_index()\n",
    "histogram_table.columns = ['Animation Length', 'Count']\n",
    "histogram_table = histogram_table.sort_values(by='Animation Length')\n",
    "print(histogram_table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1993ce2ca35e2fb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build sequences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c275faf882ee5165"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make List of all Data Samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c58b68a3c311b2f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_animations_index = best_output.groupby(['filename', 'file']).size().reset_index(name='animation_length')\n",
    "final_animations_index.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a027e3d0598f18f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logos.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd3b3aef02014751",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_animations_index = final_animations_index.merge(logos[[\"filename\",\"count\"]], on='filename', how='left')\n",
    "final_animations_index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69e7def819790306",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot: Number of Paths vs Animation Length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92d23e3b8d8e26"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the two columns for the scatter plot\n",
    "x = final_animations_index['count']\n",
    "y = final_animations_index['animation_length']\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Number of Paths')\n",
    "plt.ylabel('Animation Length')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ca6d701bd07713",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bucketing\n",
    "For batching the data later on, build buckets to group animations with similar length characteristics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78f3f68a4d6a18a0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from dataset_helper import generate_buckets_2D\n",
    "# generate_buckets_2D(final_animations_index,\n",
    "#                  'count',\n",
    "#                  'animation_length',\n",
    "#                  [0.2, 0.4, 0.6, 0.8, 1],\n",
    "#                  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75fcf5fb0173ddc8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Input Sequences Dictionary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a17d5e8dfdf0ccad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_input_sequences_dict(sequences: pd.DataFrame, used_paths: pd.DataFrame, is_used_path_filtering = False):\n",
    "    if is_used_path_filtering:\n",
    "        initial_length = len(sequences)\n",
    "        used_paths['animation_id'] = used_paths['animation_id'].astype(str)\n",
    "        sequences = pd.merge(sequences, used_paths, on=['filename', 'animation_id']).copy()\n",
    "        print(f\"Filtering of input sequences on only used paths. Reduction from {initial_length} to {len(sequences)} paths.\")\n",
    "\n",
    "    dict = {}\n",
    "    for logo in sequences[\"filename\"].unique():\n",
    "        dict[logo] = sequences[sequences[\"filename\"]==logo]\n",
    "    \n",
    "    return dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "780998277f9d4711",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_sequences_dict = build_input_sequences_dict(input_sequences, used_paths, is_used_path_filtering=True)\n",
    "input_sequences_dict[logos_train[0]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "943e35dc5224463f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Output Sequence (Embedded Paths with Animation Vector)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5c4d172ac435313"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge Dataframes\n",
    "output_sequence = pd.merge(best_output, embeddings, on=['filename', 'animation_id'], how='inner')\n",
    "animation_vectors = pd.DataFrame(output_sequence[\"model_output\"].to_list(), columns=[\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"a7\",\"a8\",\"a9\",\"a10\",\"a11\",\"a12\"])\n",
    "output_sequence.drop(['animation_id', 'model_output', 'label', 'rating', 'average_rating'], inplace=True, axis=1)\n",
    "output_sequence['a0'] = 0 # EOS Feature in One-hot Encoding\n",
    "output_sequence = pd.merge(output_sequence, animation_vectors, left_index=True, right_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d18f41c9c48fadaa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Move column 'a13' to the back\n",
    "column_to_move = 'a13'\n",
    "new_order = [col for col in output_sequence.columns if col != column_to_move]\n",
    "new_order.append(column_to_move)\n",
    "output_sequence = output_sequence[new_order]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f784f4c91bdacac9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output_sequence.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537e9ae98abafa69",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Iteration over all samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64ab015708e37e45"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dataset_helper import generate_dataset\n",
    "\n",
    "dataset = generate_dataset(final_animations_index,\n",
    "                           input_sequences_dict,\n",
    "                           output_sequence,\n",
    "                           {\"train\": logos_train, \"test\": logos_test},\n",
    "                           sequence_length_input=8, # low as filtered\n",
    "                           sequence_length_output=15, # input length\n",
    "                           )\n",
    "# Executed in 1 minute with shortened padding ~Cornelius"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d24882ae1dbd062",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7feefc1437db2296"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(dataset[\"train\"][\"input\"], 'data/prototype_dataset/train_sequence_input.pt')\n",
    "torch.save(dataset[\"train\"][\"output\"], 'data/prototype_dataset/train_sequence_output.pt')\n",
    "torch.save(dataset[\"test\"][\"input\"], 'data/prototype_dataset/test_sequence_input.pt')\n",
    "torch.save(dataset[\"test\"][\"output\"], 'data/prototype_dataset/test_sequence_output.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "406980343f8a8e3b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(dataset[\"train\"][\"input\"].size())\n",
    "print(dataset[\"train\"][\"output\"].size())\n",
    "print(dataset[\"test\"][\"input\"].size())\n",
    "print(dataset[\"test\"][\"output\"].size())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30808dff14160db9",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
