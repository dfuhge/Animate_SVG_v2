{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87acc6b5c53311e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prototype Dataset\n",
    "This file generates the path-to-path dataset to train a prototype transformer\n",
    "\n",
    "The input output sequence of a logo should consist of 270 Parameters\n",
    "- DeepSVG Embedding (256)\n",
    "- a0 Type \"EOS\" (1)\n",
    "- a1 - a6 Type (6)\n",
    "- a7 - a12 Param (6)\n",
    "- a13 time offset from beginning of animation in seconds\n",
    "\n",
    "Input Sequence\n",
    "- In the input sequence, the last 13 Parameters are set to zero\n",
    "- In a final model, these parameters are aimed to be left out (as context vector isn't based on that)\n",
    "\n",
    "Output Sequence\n",
    "- The Output sequence consists of the selected paths represented by their DeepSVG Embedding\n",
    "- The Animation is represented through the type and the parameters.\n",
    "- Each output sequence ends with an EOS Token, where the EOS-type in the one-hot-encoded part is set to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ccfdc",
   "metadata": {},
   "source": [
    "## Creating the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "# Initialize Firebase Admin SDK with your service account credentials\n",
    "cred = credentials.Certificate(\"rate-logos-firebase-adminsdk-9tvce-74b6eadb1d.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "\n",
    "# Create a reference to the Firestore database\n",
    "db = firestore.client()\n",
    "\n",
    "# Reference to your Firestore collection\n",
    "collection_ref = db.collection(\"animations_new\")\n",
    "\n",
    "# Get documents from the collection\n",
    "documents = collection_ref.stream()\n",
    "\n",
    "# Create a list to store data\n",
    "data = []\n",
    "\n",
    "# Iterate over documents and extract data\n",
    "for doc in documents:\n",
    "    data.append(doc.to_dict())\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "df.to_csv('data/ratings/test_rating.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d788a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = 'data/5_svg_embedding/svg_embedding_5000.pkl'\n",
    "\n",
    "# Open the pickle file for reading in binary mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the data from the pickle file\n",
    "    data = pickle.load(file)\n",
    "\n",
    "#filtered_data = pd.read_csv(\"data/animated_svgs_dataframes/firebase_animations.csv\", sep=\";\").rename(columns={\"filename\":\"file\", \"rating\" : \"label\"})\n",
    "#data[\"filename\"]=data[\"filename\"].str.replace(\".svg\",\"\")\n",
    "#test = pd.merge(data, filtered_data, left_on=\"filename\", right_on=\"file\", how=\"inner\")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c42a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of paths \n",
    "\n",
    "data['filename'].value_counts()\n",
    "data[\"filename\"]=data[\"filename\"].str.replace(\".svg\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_distribution = data['filename'].value_counts()\n",
    "count_distribution.plot(kind='bar')\n",
    "plt.xlabel('Unique Values')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count Distribution of Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['filename'], bins=20)  # You can adjust the number of bins as needed\n",
    "plt.xlabel('Unique Values')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count Distribution of Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max number of paths in one logo\n",
    "data['filename'].value_counts().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['filename']=='logo_36']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94257ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data['animation_id'][118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV into DataFrame\n",
    "df = pd.read_csv('data/ratings/test_rating.csv')\n",
    "\n",
    "df['id'] = df.index\n",
    "\n",
    "# separating to rating and animation\n",
    "animation_df = df[['id','filename','data', \"rating\"]]\n",
    "\n",
    "rating_df = df[['id','filename','rating']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea37d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the structure of rating data \n",
    "\n",
    "# Split the 'data' column and explode\n",
    "animation_df['data'] = animation_df['data'].str.rstrip(';').str.split(';')\n",
    "animation_df = animation_df.explode('data').dropna()\n",
    "\n",
    "# Reset the index\n",
    "animation_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# separating the animation ids and animation params\n",
    "animation_df[['animation_id','a_0','a_1','a_2','a_3','a_4','a_5','a_6','a_7','a_8','a_9',\n",
    "           'a_10','a_11','a_12','a_13','a_14','a_15','a_16','a_17','a_18','a_19','a_20','a_21',\n",
    "           'a_22','a_23','a_24','a_25']] = animation_df['data'].str.split(',', expand=True)\n",
    "\n",
    "animation_df[['animation_id']] = animation_df[['animation_id']].astype(int)\n",
    "\n",
    "animation_df[['a_0','a_1','a_2','a_3','a_4','a_5','a_6','a_7','a_8','a_9',\n",
    "           'a_10','a_11','a_12','a_13','a_14','a_15','a_16','a_17','a_18','a_19','a_20','a_21',\n",
    "           'a_22','a_23','a_24','a_25']] = animation_df[['a_0','a_1','a_2','a_3','a_4','a_5','a_6','a_7','a_8','a_9',\n",
    "           'a_10','a_11','a_12','a_13','a_14','a_15','a_16','a_17','a_18','a_19','a_20','a_21',\n",
    "           'a_22','a_23','a_24','a_25']].astype(float)\n",
    "\n",
    "# Create a new column with concatenated values from each row\n",
    "animation_df['model_output'] = animation_df[['a_0','a_1','a_2','a_3','a_4','a_5','a_6','a_7','a_8','a_9',\n",
    "           'a_10','a_11','a_12','a_13','a_14','a_15','a_16','a_17','a_18','a_19','a_20','a_21',\n",
    "           'a_22','a_23','a_24','a_25']].apply(lambda row: list(row), axis=1)\n",
    "\n",
    "animation_df.drop(columns=['data','a_0','a_1','a_2','a_3','a_4','a_5','a_6','a_7','a_8','a_9',\n",
    "           'a_10','a_11','a_12','a_13','a_14','a_15','a_16','a_17','a_18','a_19','a_20','a_21',\n",
    "           'a_22','a_23','a_24','a_25'], inplace=True)\n",
    "\n",
    "animation_df.to_csv(\"data/animated_svgs_dataframes/firebase_animations.csv\", sep=\";\")\n",
    "animation_df[\"model_output\"] = list(animation_df[\"model_output\"])\n",
    "animation_df[\"model_output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5224e8",
   "metadata": {},
   "source": [
    "## PROTOTYPE DATASET START"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc106e338f0e309d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import DeepSVG Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68694a80615a4275",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "with open(\"data/5_svg_embedding/svg_embedding_5000.pkl\", \"rb\") as f:\n",
    "    deepsvg_embedding = pickle.load(f)\n",
    "deepsvg_embedding[\"filename\"] = deepsvg_embedding[\"filename\"].str.replace(\".svg\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59123a29038005",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## duplicate for further use\n",
    "embeddings = deepsvg_embedding.copy() #for output sequences\n",
    "input_sequences = deepsvg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da861ad9f01a944",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings['animation_id'] = embeddings['animation_id'].astype(int)\n",
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e48324318b5982",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd22cb0cffcf0c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Logo Dataset Analysis\n",
    "Most logos have only a few paths\n",
    "Some logos have over 100 paths to animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9597e294788436",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Might not execute\n",
    "# input_sequences['filename'].value_counts().hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7e27502d643b9f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stratify on Number of Paths in Logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582414bf00ab129",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count occurrences\n",
    "logos = input_sequences.groupby('filename').size().reset_index(name='count')\n",
    "\n",
    "# To stratify later, categorize the sizes\n",
    "bins = 20\n",
    "quantiles = [(i+1)/bins for i in range(bins)]\n",
    "print(quantiles)\n",
    "\n",
    "percentiles = logos['count'].quantile(quantiles)\n",
    "print(percentiles)\n",
    "\n",
    "# Function to categorize based on quantiles\n",
    "def categorize_count(count):\n",
    "    for i, percentile in enumerate(percentiles):\n",
    "        if count <= percentile:\n",
    "            return f\"Quantile {i}\"\n",
    "    return f\"Quantile {len(quantiles)}\"\n",
    "\n",
    "# Apply the categorization function to create a new column\n",
    "logos['count_category'] = logos['count'].apply(categorize_count)\n",
    "logos['count_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1f7e2888b5286",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3983833dc6366e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into training and testing sets, stratifying on 'count_category'\n",
    "logos_train, logos_test = train_test_split(logos, test_size=0.2, stratify=logos['count_category'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c87d7ce1b548",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The distributions of lenghts are now similar. Outliers with a long sequence are in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5d435c3bcd9ae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logos_train['count'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0b877551cca13",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logos_test['count'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab461f488d5804",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logos_test = logos_test['filename'].unique()\n",
    "logos_train = logos_train['filename'].unique()\n",
    "logos_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef715b269a0ba0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Discussion\n",
    "- One might also stratify over used animation types.\n",
    "- Are there enough good animations in the dataset for logos with lots of paths? -> Manual annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a75939346578e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Animation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf07bef2aec2144",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file\n",
    "with open(\"data/surrogate_model/animation_label.pkl\", \"rb\") as f:\n",
    "    imported_pickle = pickle.load(f)\n",
    "\n",
    "# Create a DataFrame from the imported data\n",
    "filtered_data = pd.DataFrame(imported_pickle, columns=[\"file\", \"animation_id\", \"model_output\", \"label\"])\n",
    "\n",
    "filtered_data = pd.read_csv(\"data/animated_svgs_dataframes/firebase_animations.csv\", sep=\";\").rename(columns={\"filename\":\"file\", \"rating\" : \"label\"})\n",
    "\n",
    "# Define the mapping for ratings\n",
    "#mapping_dict = {\"Very Good\": 6, \"Good\": 5, \"Okay\": 4, \"Bad\": 3, \"Very Bad\": 2, \"no_rating\": 1}\n",
    "# Replace the 'label' column with the corresponding ratings using .map\n",
    "#filtered_data['rating'] = filtered_data['label'].map(mapping_dict)\n",
    "filtered_data['rating'] = filtered_data['label']\n",
    "\n",
    "filtered_data[\"file\"] = filtered_data[\"file\"].str.replace(\".svg\",\"\")\n",
    "# Extract unique logos by splitting 'file' with \"_animation\" and using .str.get(0)\n",
    "#logos_unique = filtered_data['file'].str.split('_animation').str.get(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130243845ed47e58",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#example\n",
    "filtered_data[filtered_data[\"file\"].str.contains(\"logo_5\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fdd76c4de39468",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Consistency: Delete twice animated paths in one animation\n",
    "Every animation should animate each path only once. **But there are duplicates.**\n",
    "Some duplicates are completely equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb637cf25418b6ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "filtered_data[filtered_data['file'] == \"logo_379_animation_5\"]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbc95347ff1656",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SIMPLE DUPLICATE REDUCTION\n",
    "print(f\"There are {filtered_data.duplicated(subset=['file', 'animation_id'], keep=False).sum()} duplicates.\")\n",
    "\n",
    "# Create a copy for and convert numpy to strings\n",
    "duplicate_search = filtered_data.copy()\n",
    "duplicate_search['model_output'] = duplicate_search['model_output'].apply(lambda x: str(x))\n",
    "\n",
    "# Find duplicates in the copy and remove with a mask\n",
    "duplicates_mask = duplicate_search.duplicated(keep='first')\n",
    "filtered_data = filtered_data[~duplicates_mask]\n",
    "\n",
    "print(f\"Reduced to {filtered_data.duplicated(subset=['file', 'animation_id'], keep=False).sum()} duplicates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2d7767be07d8c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "But there are some more duplicates. Some have different ratings, so let's simply keep the better rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a431fce7451a3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "duplicates_mask = filtered_data.duplicated(subset=['file', 'animation_id'], keep=False)\n",
    "filtered_data[duplicates_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395f5f9c8fc8e87",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'file', 'animation_id' (for grouping) and 'rating' (descending order to prioritize higher ratings)\n",
    "filtered_data_sorted = filtered_data.sort_values(by=['file', 'animation_id', 'rating'], ascending=[True, True, False])\n",
    "\n",
    "# Mark duplicates, keeping the row with the highest rating\n",
    "duplicates_mask = filtered_data_sorted.duplicated(subset=['file', 'animation_id'], keep='first')\n",
    "\n",
    "# Identify the indices of rows to keep and filter the original DataFrame\n",
    "indices_to_keep = filtered_data_sorted[~duplicates_mask].index\n",
    "\n",
    "filtered_data = filtered_data.loc[filtered_data.index.intersection(indices_to_keep)]\n",
    "\n",
    "print(f\"Reduced to {filtered_data.duplicated(subset=['file', 'animation_id'], keep=False).sum()} duplicates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4a5ee92e9187a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now all duplicates are gone. Let's check with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f680ae079114a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check: Should be 7 animations instead of 14 \n",
    "filtered_data[filtered_data['file'] == \"logo_379\"]  # EG: logo_379_animation_5 , logo_334_animation_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052ef4a1b3a6fd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f707d3a85a731",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Some Statistics about the Animations we have here\n",
    "Result: Many animations with only one animated path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff5a562cb6b276",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = filtered_data.groupby('file').count()\n",
    "grouped = grouped[['animation_id']]\n",
    "print(f\"{grouped.size} Animations initially\")\n",
    "histogram_table = grouped['animation_id'].value_counts().reset_index()\n",
    "histogram_table.columns = ['Animation Length', 'Count']\n",
    "histogram_table = histogram_table.sort_values(by='Animation Length')\n",
    "print(histogram_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860151ed1d201f65",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = filtered_data.groupby('label').count()\n",
    "grouped = grouped[['file']].reset_index()\n",
    "grouped.columns = ['Rating', 'Count']\n",
    "grouped['Percentage'] = (grouped['Count'] / grouped['Count'].sum()) * 100\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e263ddaf7b9683",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Investigate overall rating of animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd67fe9b288f9ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_data['average_rating'] = filtered_data.groupby('file')['rating'].transform('mean')\n",
    "filtered_data['average_rating'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c21c5337932e58",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example\n",
    "filtered_data[filtered_data[\"file\"].str.contains(\"logo_5_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca51f1073850a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Now pick good Animations only\n",
    "Pick the following animations\n",
    "- Best per logo (include as many different logos as possible)\n",
    "- Add all GOOD animations (additionally add as many animations as possible) TODO: Implement later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5419a3d2a1cee39",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_data['include'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9be0678e5523f9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use all animations with an average rating over 3\n",
    "minimum_rating = 3\n",
    "temp = filtered_data['average_rating'] > minimum_rating\n",
    "filtered_data.loc[temp, 'include'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23571e53d0ce3431",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"{filtered_data['include'].mean() * 100}% of the data is left out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89768ae8bf1f84a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# go through each logo to find the best animation\n",
    "for logo in logos:\n",
    "    # make a data frame that contains all the animations of one logo\n",
    "    temp = filtered_data[filtered_data[\"file\"].str.contains(logo)]\n",
    "\n",
    "    best_logo = temp[temp['average_rating'] == temp['average_rating'].max()]\n",
    "    best_logo = best_logo['file'].unique()\n",
    "    \n",
    "    filtered_data.loc[filtered_data['file'].isin(best_logo), 'include'] = 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb126468661dfd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Now {filtered_data['include'].mean() * 100}% of the data is left out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89401a51abb04eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note: No additional animations are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8596ed60930653",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_output = filtered_data[filtered_data['include'] == 1].copy()\n",
    "best_output.drop(columns=['include'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b015491ede981",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract logo\n",
    "pattern = r'(logo_\\d+)'\n",
    "best_output['filename'] = best_output['file'].str.extract(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333d519facdacd5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Numeration to keep order later (corresponds to start-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb50787fb7ba2d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Create a time_offset column filled with zeros\n",
    "# best_output['a13'] = 0.0\n",
    "\n",
    "# # Define animation start time offset in seconds from animation start\n",
    "# TIME_OFFSET_STEP = 0.25\n",
    "\n",
    "# # Initialize a dictionary to store numbering for each file\n",
    "# file_counts = {}\n",
    "\n",
    "# # Iterate through the \"file\" column and number each unique file\n",
    "# for index, row in best_output.iterrows():\n",
    "#     filename = row['file']\n",
    "#     if filename not in file_counts:\n",
    "#         file_counts[filename] = 1\n",
    "#     else:\n",
    "#         file_counts[filename] += 1\n",
    "#     best_output.at[index, 'a13'] = file_counts[filename] * TIME_OFFSET_STEP\n",
    "# best_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810cac385fb0ab0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stat: Animated paths per logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37720cb3f400d63a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "used_paths = best_output[[\"filename\", \"animation_id\"]].drop_duplicates(\n",
    "    subset = ['filename', 'animation_id'], keep = 'last').reset_index(drop = True)\n",
    "used_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2b3d098c776df",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "used_paths.groupby(['filename']).count().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e427e39220f011c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Some Statistics again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1993ce2ca35e2fb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = best_output.groupby('file').count()\n",
    "grouped = grouped[['animation_id']]\n",
    "print(f\"{grouped.size} Animations left over\")\n",
    "histogram_table = grouped['animation_id'].value_counts().reset_index()\n",
    "histogram_table.columns = ['Animation Length', 'Count']\n",
    "histogram_table = histogram_table.sort_values(by='Animation Length')\n",
    "print(histogram_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275faf882ee5165",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Build sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b68a3c311b2f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Make List of all Data Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3906fa42e40c6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Apply Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb9ffd4acd8635",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_animation_stats = best_output[['filename', 'file', 'model_output']].copy()\n",
    "final_animation_stats['animation_length'] = 1\n",
    "for i in range(26):\n",
    " final_animation_stats[f'a{i}'] = final_animation_stats['model_output'].apply(lambda x: float(x.split(\",\")[i].replace(\"[\",\"\").replace(\"]\",\"\")))\n",
    "final_animation_stats.drop(['model_output'], inplace=True, axis=1)\n",
    "final_animation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203bd84128d57a27",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Group by logo & animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027e3d0598f18f0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_animations_index = final_animation_stats.groupby(['filename', 'file']).sum()\n",
    "#final_animations_index['a0'] = 1 # EOS one per animation sequence\n",
    "final_animations_index = final_animations_index.reset_index()\n",
    "final_animations_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d86190a37fc7924",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Balance and Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e96d4b7ac0450",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_animations_index['repeat'] = 1\n",
    "\n",
    "def print_balancing_stats(df: pd.DataFrame, silent=False):\n",
    "    temp = df.copy()\n",
    "    temp = temp[~temp['filename'].isin(logos_test)] # train data only\n",
    "    temp = temp.reset_index().drop(['filename', 'file','animation_length'], axis=1)\n",
    "    for i in range(0, 26):\n",
    "        temp[f'a{i}'] = temp[f'a{i}'] * temp['repeat']\n",
    "    balance = temp[[\"a0\", 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a16', 'a17', 'a18', 'a19', 'a20', 'a21', 'a22', 'a23', 'a24', 'a25']].sum()\n",
    "    balance_percentage = min(balance) / max(balance)\n",
    "    balance_diff = max(balance) - min(balance)\n",
    "    if silent:\n",
    "        return balance_diff, balance_percentage, balance.nsmallest(6).index\n",
    "    print(f\"Balanced with oversampling {int(temp['repeat'].sum() / len(temp) * 100)-100}% to {int(balance_percentage * 100)}%\")\n",
    "    print(balance)\n",
    "    \n",
    "print_balancing_stats(final_animations_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6535846bfac6305",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_balancing_stats(final_animations_index, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06dfaff1c49384",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Currently, EOS (a0) occurs much more often then the other animation types.\n",
    "\n",
    "Let's oversample all sequences > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c967c051f36b82d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_animations_index[final_animations_index['filename'] == 'logo_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c5cf743ee78df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Through oversampling, this can be optimized..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3337e8c4dc314",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Very fancy sampling\n",
    "def get_filter_mask(df, rare_animations, second_rarest=False, second_most_frequent=False, max_repetition=8):\n",
    "    if second_rarest and second_most_frequent:\n",
    "        return df.loc[(df[rare_animations[0]] > 0) & \n",
    "                      (df[rare_animations[1]] > 0) &\n",
    "                      (df[rare_animations[4]] == 0) &\n",
    "                      (df[rare_animations[5]] == 0) &\n",
    "                      (df['repeat'] < df['animation_length'] + 2) &\n",
    "                      (df['repeat'] < max_repetition)]\n",
    "    if second_rarest and not second_most_frequent:\n",
    "        return df.loc[(df[rare_animations[0]] > 0) & \n",
    "                      #(df[rare_animations[1]] > 0) &\n",
    "                      (df[rare_animations[4]] == 0) &\n",
    "                      (df[rare_animations[5]] == 0) &\n",
    "                      (df['repeat'] < df['animation_length'] + 2) &\n",
    "                      (df['repeat'] < max_repetition)]\n",
    "    if not second_rarest and second_most_frequent:\n",
    "        return df.loc[(df[rare_animations[0]] > 0) & \n",
    "                      (df[rare_animations[1]] > 0) &\n",
    "                      #(df[rare_animations[4]] == 0) &\n",
    "                      (df[rare_animations[5]] == 0) &\n",
    "                      (df['repeat'] < df['animation_length'] + 2) &\n",
    "                      (df['repeat'] < max_repetition)]\n",
    "    return df.loc[(df[rare_animations[0]] > 0) & \n",
    "                  #(df[rare_animations[1]] > 0) &\n",
    "                  #(df[rare_animations[4]] == 0) &\n",
    "                  (df[rare_animations[5]] == 0) &\n",
    "                  (df['repeat'] < df['animation_length'] + 2) &\n",
    "                  (df['repeat'] < max_repetition)]\n",
    "\n",
    "final_animations_index['repeat'] = 1\n",
    "sample_size = 5\n",
    "\n",
    "for i in range(1000):\n",
    "    balance_diff, balance, rare_animations = print_balancing_stats(final_animations_index, silent=True)\n",
    "    if balance_diff < 20:\n",
    "        sample_size = 1\n",
    "        filtering = get_filter_mask(final_animations_index, rare_animations, second_most_frequent=True, max_repetition=8)\n",
    "\n",
    "    else:\n",
    "        filtering = get_filter_mask(final_animations_index, rare_animations, second_rarest=True, second_most_frequent=True, max_repetition=6)\n",
    "        if len(filtering == 0):\n",
    "            filtering = get_filter_mask(final_animations_index, rare_animations, second_most_frequent=True, max_repetition=7)\n",
    "            if len(filtering == 0):\n",
    "                filtering = get_filter_mask(final_animations_index, rare_animations, max_repetition=8)\n",
    "            \n",
    "    if balance_diff < 20:\n",
    "        print(f\"Final oversampling: {balance_diff} difference, {len(filtering)} in filtering\")\n",
    "    if balance_diff < 2:\n",
    "        print(f\"Break after {i} Iterations\")\n",
    "        break\n",
    "\n",
    "    random_indices = filtering.sample(n=min(sample_size, len(filtering))).index.tolist()\n",
    "    final_animations_index.loc[random_indices, 'repeat'] += 1\n",
    "    \n",
    "print_balancing_stats(final_animations_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ad629e9e360a3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_animations_index['repeat'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e13e2198bf25d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the two columns for the scatter plot\n",
    "x = final_animations_index['repeat']\n",
    "y = final_animations_index['animation_length']\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Oversampling')\n",
    "plt.ylabel('Animation Length')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb86807486fe13",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_animations_index[final_animations_index['filename'] == 'logo_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35408aba08cfb2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Merge logo stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b3aef02014751",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7def819790306",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_animations_index = final_animations_index.merge(logos[[\"filename\",\"count\"]], on='filename', how='left')\n",
    "final_animations_index.rename(columns={'count': 'num_paths'}, inplace=True)\n",
    "final_animations_index[\"file\"] = final_animations_index[\"file\"].str.replace(\".svg\",\"\")\n",
    "final_animations_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d23e3b8d8e26",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Plot: Number of Paths vs Animation Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca6d701bd07713",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the two columns for the scatter plot\n",
    "x = final_animations_index['num_paths']\n",
    "y = final_animations_index['animation_length']\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Number of Paths')\n",
    "plt.ylabel('Animation Length')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f3f68a4d6a18a0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bucketing\n",
    "For batching the data later on, build buckets to group animations with similar length characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fcf5fb0173ddc8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from dataset_helper import generate_buckets_2D\n",
    "# generate_buckets_2D(final_animations_index,\n",
    "#                  'count',\n",
    "#                  'animation_length',\n",
    "#                  [0.2, 0.4, 0.6, 0.8, 1],\n",
    "#                  [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d5e8dfdf0ccad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Build Input Sequences Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780998277f9d4711",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_input_sequences_dict(sequences: pd.DataFrame, used_paths: pd.DataFrame, is_used_path_filtering = False, keep_unused=False):\n",
    "    initial_length = len(sequences)\n",
    "    used_paths['animation_id'] = used_paths['animation_id'].astype(str)\n",
    "    if is_used_path_filtering:\n",
    "        if keep_unused:\n",
    "            # If keeping unused paths, perform a left merge and then filter where used paths are NaN\n",
    "            sequences = pd.merge(sequences, used_paths, on=['filename', 'animation_id'], how='left', indicator=True)\n",
    "            sequences = sequences[sequences['_merge'] == 'left_only'].drop(columns=['_merge']).copy()\n",
    "            print(sequences)\n",
    "            print(f\"Filtering of input sequences to keep only unused paths. Reduction from {initial_length} to {len(sequences)} paths.\")\n",
    "        else:\n",
    "            # If not keeping unused paths, perform an inner merge to keep only used paths\n",
    "            sequences = pd.merge(sequences, used_paths, on=['filename', 'animation_id']).copy()\n",
    "            #print(sequences, used_paths)\n",
    "            print(f\"Filtering of input sequences on only used paths. Reduction from {initial_length} to {len(sequences)} paths.\")\n",
    "    \n",
    "    dict = {}\n",
    "    for logo in sequences[\"filename\"].unique():\n",
    "        dict[logo] = sequences[sequences[\"filename\"]==logo]\n",
    "    #print(dict)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e35dc5224463f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_sequences[\"filename\"] = input_sequences[\"filename\"].str.replace(\".svg\",\"\")\n",
    "input_sequences_dict_used = build_input_sequences_dict(input_sequences, used_paths, is_used_path_filtering=True)\n",
    "print(input_sequences_dict_used.keys())\n",
    "#input_sequences_dict_used[logos_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b833b29bbb9f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_sequences[\"filename\"] = input_sequences[\"filename\"].str.replace(\".svg\",\"\")\n",
    "input_sequences_dict_unused = build_input_sequences_dict(input_sequences, used_paths, is_used_path_filtering=True, keep_unused=True)\n",
    "#input_sequences_dict_unused[logos_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4d172ac435313",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Build Output Sequence (Embedded Paths with Animation Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f41c9c48fadaa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge Dataframes\n",
    "output_sequence = pd.merge(best_output, embeddings, on=['filename', 'animation_id'], how='inner')\n",
    "animation_vectors=pd.DataFrame()\n",
    "for i in range(26):\n",
    " animation_vectors[f'a{i}'] = output_sequence['model_output'].apply(lambda x: float(x.split(\",\")[i].replace(\"[\",\"\").replace(\"]\",\"\")))\n",
    "#animation_vectors = pd.DataFrame(output_sequence[\"model_output\"].to_list(), columns=[\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"a7\",\"a8\",\"a9\",\"a10\",\"a11\",\"a12\"])\n",
    "output_sequence.drop(['animation_id', 'model_output', 'label', 'rating', 'average_rating'], inplace=True, axis=1)\n",
    "#output_sequence['a0'] = 0 # EOS Feature in One-hot Encoding\n",
    "output_sequence = pd.merge(output_sequence, animation_vectors, left_index=True, right_index=True)\n",
    "output_sequence[\"file\"] = output_sequence[\"file\"].str.replace(\".svg\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784f4c91bdacac9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Move column 'a13' to the back\n",
    "column_to_move = 'a10'\n",
    "new_order = [col for col in output_sequence.columns if col != column_to_move]\n",
    "new_order.append(column_to_move)\n",
    "#output_sequence = output_sequence[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e9ae98abafa69",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_sequence.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab015708e37e45",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Main Iteration over all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24882ae1dbd062",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset_helper import generate_dataset\n",
    "\n",
    "\n",
    "dataset = generate_dataset(final_animations_index,\n",
    "                           input_sequences_dict_used,\n",
    "                           input_sequences_dict_unused,\n",
    "                           output_sequence,\n",
    "                           {\"train\": logos_train, \"test\": logos_test},\n",
    "                           sequence_length_input=150, # low as filtered\n",
    "                           sequence_length_output=150, # input + SOS / EOS\n",
    "                           )\n",
    "# Executed in 1 minute with shortened padding ~Cornelius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feefc1437db2296",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406980343f8a8e3b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(dataset[\"train\"][\"input\"], 'data/prototype_dataset/train_sequence_input.pt')\n",
    "torch.save(dataset[\"train\"][\"output\"], 'data/prototype_dataset/train_sequence_output.pt')\n",
    "torch.save(dataset[\"test\"][\"input\"], 'data/prototype_dataset/test_sequence_input.pt')\n",
    "torch.save(dataset[\"test\"][\"output\"], 'data/prototype_dataset/test_sequence_output.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30808dff14160db9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dataset[\"train\"][\"input\"].size())\n",
    "print(dataset[\"train\"][\"output\"].size())\n",
    "print(dataset[\"test\"][\"input\"].size())\n",
    "print(dataset[\"test\"][\"output\"].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f61ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
