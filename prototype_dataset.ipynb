{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prototype Dataset\n",
    "This file generates the path-to-path dataset to train a prototype transformer\n",
    "\n",
    "The input output sequence of a logo should consist of 269 Parameters\n",
    "- DeepSVG Embedding (256)\n",
    "- Type \"EOS\" (1) (open for discussion, but it makes the most sense in the predicting process ~Corni)\n",
    "- Type (6)\n",
    "- Param (6)\n",
    "\n",
    "Input Sequence\n",
    "- In the input sequence, the last 13 Parameters are set to zero\n",
    "- In a final model, these parameters are aimed to be left out (as context vector isn't based on that)\n",
    "\n",
    "Output Sequence\n",
    "- The Output sequence consists of the selected paths represented by their DeepSVG Embedding\n",
    "- The Animation is represented through the type and the parameters.\n",
    "- Each output sequence ends with an EOS Token, where the EOS-type in the one-hot-encoded part is set to 1."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f87acc6b5c53311e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import DeepSVG Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc106e338f0e309d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "with open(\"data/embeddings/path_embedding.pkl\", \"rb\") as f:\n",
    "    deepsvg_embedding = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68694a80615a4275",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## duplicate for further use\n",
    "embeddings = deepsvg_embedding.copy() #for output sequences\n",
    "input_sequences = deepsvg_embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb59123a29038005",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embeddings['animation_id'] = embeddings['animation_id'].astype(int)\n",
    "embeddings.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da861ad9f01a944",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train / Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6e48324318b5982"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logo Dataset Analysis\n",
    "Most logos have only a few paths\n",
    "Some logos have over 100 paths to animate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8cd22cb0cffcf0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_sequences['filename'].value_counts().hist(bins=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b9597e294788436",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stratify on Number of Paths in Logo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf7e27502d643b9f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Count occurrences\n",
    "logos = input_sequences.groupby('filename').size().reset_index(name='count')\n",
    "\n",
    "# To stratify later, categorize the sizes\n",
    "bins = 20\n",
    "quantiles = [(i+1)/bins for i in range(bins)]\n",
    "print(quantiles)\n",
    "\n",
    "percentiles = logos['count'].quantile(quantiles)\n",
    "print(percentiles)\n",
    "\n",
    "# Function to categorize based on quantiles\n",
    "def categorize_count(count):\n",
    "    for i, percentile in enumerate(percentiles):\n",
    "        if count <= percentile:\n",
    "            return f\"Quantile {i}\"\n",
    "    return f\"Quantile {len(quantiles)}\"\n",
    "\n",
    "# Apply the categorization function to create a new column\n",
    "logos['count_category'] = logos['count'].apply(categorize_count)\n",
    "logos['count_category'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d582414bf00ab129",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train / Test split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7f1f7e2888b5286"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into training and testing sets, stratifying on 'count_category'\n",
    "logos_train, logos_test = train_test_split(logos, test_size=0.2, stratify=logos['count_category'], random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d3983833dc6366e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The distributions of lenghts are now similar. Outliers with a long sequence are in both datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b4c87d7ce1b548"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logos_train['count'].hist(bins=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36a5d435c3bcd9ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logos_test['count'].hist(bins=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da0b877551cca13",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logos_test = logos_test['filename'].unique()\n",
    "logos_train = logos_train['filename'].unique()\n",
    "logos_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bab461f488d5804",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "- One might also stratify over used animation types.\n",
    "- Are there enough good animations in the dataset for logos with lots of paths? -> Manual annotation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81ef715b269a0ba0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Animation Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a75939346578e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file\n",
    "with open(\"data/surrogate_model/animation_label.pkl\", \"rb\") as f:\n",
    "    imported_pickle = pickle.load(f)\n",
    "\n",
    "# Create a DataFrame from the imported data\n",
    "filtered_data = pd.DataFrame(imported_pickle, columns=[\"file\", \"animation_id\", \"model_output\", \"label\"])\n",
    "\n",
    "# Define the mapping for ratings\n",
    "mapping_dict = {\"Very Good\": 6, \"Good\": 5, \"Okay\": 4, \"Bad\": 3, \"Very Bad\": 2, \"no_rating\": 1}\n",
    "\n",
    "# Replace the 'label' column with the corresponding ratings using .map\n",
    "filtered_data['rating'] = filtered_data['label'].map(mapping_dict)\n",
    "\n",
    "# Extract unique logos by splitting 'file' with \"_animation\" and using .str.get(0)\n",
    "#logos_unique = filtered_data['file'].str.split('_animation').str.get(0).unique()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbf07bef2aec2144",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#example\n",
    "filtered_data[filtered_data[\"file\"].str.contains(\"logo_5_\")]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "130243845ed47e58",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some Statistics about the Animations we have here\n",
    "Result: Many animations with only one animated path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a27f707d3a85a731"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = filtered_data.groupby('file').count()\n",
    "grouped = grouped[['animation_id']]\n",
    "print(f\"{grouped.size} Animations initially\")\n",
    "histogram_table = grouped['animation_id'].value_counts().reset_index()\n",
    "histogram_table.columns = ['Animation Length', 'Count']\n",
    "histogram_table = histogram_table.sort_values(by='Animation Length')\n",
    "print(histogram_table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9ff5a562cb6b276",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = filtered_data.groupby('label').count()\n",
    "grouped = grouped[['file']].reset_index()\n",
    "grouped.columns = ['Rating', 'Count']\n",
    "grouped['Percentage'] = (grouped['Count'] / grouped['Count'].sum()) * 100\n",
    "grouped"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "860151ed1d201f65",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Investigate overall rating of animations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32e263ddaf7b9683"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data['average_rating'] = filtered_data.groupby('file')['rating'].transform('mean')\n",
    "filtered_data['average_rating'].hist(bins=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbd67fe9b288f9ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# example\n",
    "filtered_data[filtered_data[\"file\"].str.contains(\"logo_5_\")]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c21c5337932e58",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now pick good Animations only\n",
    "Pick the following animations\n",
    "- Best per logo (include as many different logos as possible)\n",
    "- Add all GOOD animations (additionally add as many animations as possible) TODO: Implement later"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ca51f1073850a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_data['include'] = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5419a3d2a1cee39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# use all animations with an average rating over 3\n",
    "minimum_rating = 3\n",
    "temp = filtered_data['average_rating'] > minimum_rating\n",
    "filtered_data.loc[temp, 'include'] = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de9be0678e5523f9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"{filtered_data['include'].mean() * 100}% of the data is left out\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23571e53d0ce3431",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# go through each logo to find the best animation\n",
    "for logo in logos:\n",
    "    # make a data frame that contains all the animations of one logo\n",
    "    temp = filtered_data[filtered_data[\"file\"].str.contains(logo)]\n",
    "\n",
    "    best_logo = temp[temp['average_rating'] == temp['average_rating'].max()]\n",
    "    best_logo = best_logo['file'].unique()\n",
    "    \n",
    "    filtered_data.loc[filtered_data['file'].isin(best_logo), 'include'] = 1\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89768ae8bf1f84a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Now {filtered_data['include'].mean() * 100}% of the data is left out\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebb126468661dfd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: No additional animations are selected"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b89401a51abb04eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_output = filtered_data[filtered_data['include'] == 1].copy()\n",
    "best_output.drop(columns=['include'], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d8596ed60930653",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract logo\n",
    "pattern = r'(logo_\\d+)'\n",
    "best_output['filename'] = best_output['file'].str.extract(pattern)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b015491ede981",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Numeration to keep order later (corresponds to start-time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7333d519facdacd5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create an empty \"count\" column filled with zeros\n",
    "best_output['order'] = 0\n",
    "\n",
    "# Initialize a dictionary to store numbering for each file\n",
    "file_counts = {}\n",
    "\n",
    "# Iterate through the \"file\" column and number each unique file\n",
    "for index, row in best_output.iterrows():\n",
    "    filename = row['file']\n",
    "    if filename not in file_counts:\n",
    "        file_counts[filename] = 1\n",
    "    else:\n",
    "        file_counts[filename] += 1\n",
    "    best_output.at[index, 'order'] = file_counts[filename]\n",
    "best_output.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eb50787fb7ba2d1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some Statistics again\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e427e39220f011c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grouped = best_output.groupby('file').count()\n",
    "grouped = grouped[['animation_id']]\n",
    "print(f\"{grouped.size} Animations left over\")\n",
    "histogram_table = grouped['animation_id'].value_counts().reset_index()\n",
    "histogram_table.columns = ['Animation Length', 'Count']\n",
    "histogram_table = histogram_table.sort_values(by='Animation Length')\n",
    "print(histogram_table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1993ce2ca35e2fb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build sequences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c275faf882ee5165"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make List of all Data Samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c58b68a3c311b2f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_animations_index = best_output.groupby(['filename', 'file']).size().reset_index(name='animation_length')\n",
    "final_animations_index.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a027e3d0598f18f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logos.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd3b3aef02014751",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_animations_index = final_animations_index.merge(logos[[\"filename\",\"count\"]], on='filename', how='left')\n",
    "final_animations_index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69e7def819790306",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot: Number of Paths vs Animation Length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92d23e3b8d8e26"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the two columns for the scatter plot\n",
    "x = final_animations_index['count']\n",
    "y = final_animations_index['animation_length']\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Number of Paths')\n",
    "plt.ylabel('Animation Length')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ca6d701bd07713",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Input Sequences Dictionary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a17d5e8dfdf0ccad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_sequences_dict = {}\n",
    "for logo in input_sequences[\"filename\"].unique():\n",
    "    input_sequences_dict[logo] = input_sequences[input_sequences[\"filename\"]==logo]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "118abeafdbfa5701",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# example\n",
    "print(logos_train[0])\n",
    "input_sequences_dict[logos_train[0]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8183152eb25846",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Output Sequence (Embedded Paths with Animation Vector)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5c4d172ac435313"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge Dataframes\n",
    "output_sequence = pd.merge(best_output, embeddings, on=['filename', 'animation_id'], how='inner')\n",
    "animation_vectors = pd.DataFrame(output_sequence[\"model_output\"].to_list(), columns=[\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"a7\",\"a8\",\"a9\",\"a10\",\"a11\",\"a12\"])\n",
    "output_sequence.drop(['animation_id', 'model_output', 'label', 'rating', 'average_rating'], inplace=True, axis=1)\n",
    "output_sequence['a0'] = 0 # EOS Feature in One-hot Encoding\n",
    "output_sequence = pd.merge(output_sequence, animation_vectors, left_index=True, right_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d18f41c9c48fadaa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output_sequence.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537e9ae98abafa69",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Iteration over all samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64ab015708e37e45"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PADDING_VALUE = float('-inf')\n",
    "\n",
    "def generate_input_sequence(logo_embeddings: pd.DataFrame, null_features: int, sequence_length : int, is_randomized : bool) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Build a torch tensor for the transformer input sequences.\n",
    "    Includes\n",
    "    - Randomization (optional)\n",
    "    - Generation of padding\n",
    "    \n",
    "    Args:\n",
    "        is_randomized: shuffle order of paths\n",
    "        logo_embeddings (pd.DataFrame): DataFrame containing logo embeddings.\n",
    "        null_features (int): Number of null features to add to each embedding.\n",
    "        sequence_length (int): Target length for padding sequences.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor representing the input sequences.\n",
    "    \"\"\"\n",
    "    logo_embeddings.drop(columns=['filename', 'animation_id'], inplace=True)\n",
    "    \n",
    "    # Randomization\n",
    "    if is_randomized:\n",
    "        logo_embeddings = logo_embeddings.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Null Features\n",
    "    if null_features > 0:\n",
    "        logo_embeddings = pd.concat([logo_embeddings,\n",
    "                                     pd.DataFrame(0,\n",
    "                                                  index=logo_embeddings.index,\n",
    "                                                  columns=range(logo_embeddings.shape[1],\n",
    "                                                                logo_embeddings.shape[1] + null_features))],\n",
    "                                    axis=1,\n",
    "                                    ignore_index=True)\n",
    "    \n",
    "    # Padding Generation: Add padding rows or cut off excess rows\n",
    "    if len(logo_embeddings) < sequence_length:\n",
    "        padding_rows = pd.DataFrame([[PADDING_VALUE] * len(logo_embeddings.columns)] * (sequence_length - len(logo_embeddings)),\n",
    "                                    columns=logo_embeddings.columns)\n",
    "        logo_embeddings = pd.concat([logo_embeddings, padding_rows], ignore_index=True)\n",
    "    elif len(logo_embeddings) > sequence_length:\n",
    "        # Cut off excess rows\n",
    "        logo_embeddings = logo_embeddings.iloc[:sequence_length]\n",
    "    \n",
    "    return torch.tensor(logo_embeddings.values)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93b79004419a7e56",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "EOS_TOKEN = float('-inf')\n",
    "def generate_output_sequence(animation: pd.DataFrame, sequence_length: int, is_randomized : bool) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Build a torch tensor for the transformer output sequences.\n",
    "    Includes\n",
    "    - Randomization (later, when same start time)\n",
    "    - Generation of padding\n",
    "    - Add EOS Token\n",
    "\n",
    "    Args:\n",
    "        is_randomized: shuffle order of paths, applies when same start time\n",
    "        animation (pd.DataFrame): DataFrame containing logo embeddings.\n",
    "        sequence_length (int): Target length for padding sequences.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor representing the input sequences.\n",
    "    \"\"\"\n",
    "    if is_randomized:\n",
    "        animation = animation.sample(frac=1).reset_index(drop=True)\n",
    "        print(\"Note: Randomization not implemented yet\")\n",
    "    \n",
    "    animation.sort_values(by=['order'], inplace=True) # again ordered by order or time start.\n",
    "    animation.drop(columns=['file', 'filename', 'order'], inplace=True)\n",
    "    \n",
    "    # Append the EOS row to the DataFrame\n",
    "    sos_eos_row = {col: 0 for col in animation.columns}\n",
    "    sos_eos_row[\"a0\"] = 1\n",
    "    animation = pd.concat([pd.DataFrame([sos_eos_row]),\n",
    "                           animation,\n",
    "                           pd.DataFrame([sos_eos_row])], ignore_index=True)\n",
    "    \n",
    "    # Padding Generation: Add padding rows or cut off excess rows\n",
    "    if len(animation) < sequence_length:\n",
    "        padding_rows = pd.DataFrame([[PADDING_VALUE] * len(animation.columns)] * (sequence_length - len(animation)),\n",
    "                                    columns=animation.columns)\n",
    "        animation = pd.concat([animation, padding_rows], ignore_index=True)\n",
    "    elif len(animation) > sequence_length:\n",
    "        # Cut off excess rows\n",
    "        animation = animation.iloc[:sequence_length]\n",
    "\n",
    "    return torch.Tensor(animation.values)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0a6d4b7690e91e2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_sequence_input_list = []\n",
    "train_sequence_output_list = []\n",
    "test_sequence_input_list = []\n",
    "test_sequence_output_list = []\n",
    "\n",
    "for i, logo_info in final_animations_index.iterrows():\n",
    "    logo = logo_info['filename']     # e.g. logo_1\n",
    "    file = logo_info['file']             # e.g. logo_1_animation_2\n",
    "    print(f\"Processing {logo} with {file}\")\n",
    "    \n",
    "    input_tensor = generate_input_sequence(input_sequences_dict[logo].copy(),\n",
    "                                           null_features=13, #TODO depends on architecture later\n",
    "                                           sequence_length=128, #TODO design question: Max elements per Logo? \n",
    "                                           is_randomized=True)\n",
    "    \n",
    "    output_tensor = generate_output_sequence(output_sequence[(output_sequence['filename'] == logo) & (output_sequence['file'] == file)].copy(),\n",
    "                                             sequence_length=15, #TODO Currently the max length of animations + 1 for EOS\n",
    "                                             is_randomized=False)\n",
    "    # append to lists\n",
    "    if logo in logos_train:\n",
    "        train_sequence_input_list.append(input_tensor)\n",
    "        train_sequence_output_list.append(output_tensor)\n",
    "        \n",
    "    elif logo in logos_test:\n",
    "        test_sequence_input_list.append(input_tensor)\n",
    "        test_sequence_output_list.append(output_tensor)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Some problem with {logo}. Neither in train or test set list.\")\n",
    "        \n",
    "# Executed in 4 minutes ~Cornelius"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a91d45a0db672a46",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7feefc1437db2296"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_sequence_input = torch.stack(train_sequence_input_list)\n",
    "train_sequence_output = torch.stack(train_sequence_output_list)\n",
    "test_sequence_input = torch.stack(test_sequence_input_list)\n",
    "test_sequence_output = torch.stack(test_sequence_output_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "120eeabb23d6c59e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(train_sequence_input.shape)\n",
    "print(train_sequence_output.shape)\n",
    "print(test_sequence_input.shape)\n",
    "print(test_sequence_output.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "827c0b54d1e50143",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(train_sequence_input, 'data/prototype_dataset/train_sequence_input.pt')\n",
    "torch.save(train_sequence_output, 'data/prototype_dataset/train_sequence_output.pt')\n",
    "torch.save(test_sequence_input, 'data/prototype_dataset/test_sequence_input.pt')\n",
    "torch.save(test_sequence_output, 'data/prototype_dataset/test_sequence_output.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "406980343f8a8e3b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
