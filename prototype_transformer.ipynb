{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785e23fb7a10fac6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Transformer Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ba02f4cf97389",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c03b7821046028",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "508e547be8863b4c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\okan2\\\\Desktop\\\\team project\\\\Animate_SVG_v2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CustomLoss import CustomEmbeddingSliceLoss\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import os\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "#transformer\n",
    "NUM_HEADS = 47 # Dividers of 282: {1, 2, 3, 6, 47, 94, 141, 282}\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 6\n",
    "DROPOUT=0.1\n",
    "\n",
    "# Methods\n",
    "loss_function = CustomEmbeddingSliceLoss()\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38275f8024e6a423",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acf2a0f340d6c6fc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "FEATURE_DIM = 282"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0797527f3ff4a27",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Prepared Tensors from Disk\n",
    "Run file `prototype_dataset.ipynb` first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee9854fe06e9ade1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_sequence_input = torch.load('data/prototype_dataset/train_sequence_input.pt')\n",
    "train_sequence_output = torch.load('data/prototype_dataset/train_sequence_output.pt')\n",
    "test_sequence_input = torch.load('data/prototype_dataset/test_sequence_input.pt')\n",
    "test_sequence_output = torch.load('data/prototype_dataset/test_sequence_output.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a0db6b3ad420b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset_helper import warn_if_contains_NaN\n",
    "\n",
    "warn_if_contains_NaN(train_sequence_input)\n",
    "warn_if_contains_NaN(train_sequence_output)\n",
    "warn_if_contains_NaN(test_sequence_input)\n",
    "warn_if_contains_NaN(test_sequence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29c9d0622c6c09e8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2598, 95, 282])\n",
      "torch.Size([2598, 95, 282])\n",
      "torch.Size([233, 95, 282])\n",
      "torch.Size([233, 95, 282])\n"
     ]
    }
   ],
   "source": [
    "print(train_sequence_input.size())\n",
    "print(train_sequence_output.size())\n",
    "print(test_sequence_input.size())\n",
    "print(test_sequence_output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78852276c50093a0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Build Dataloader with Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataloader = DataLoader(TensorDataset(train_sequence_input.float(), train_sequence_output.float()),\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "val_dataloader = DataLoader(TensorDataset(test_sequence_input.float(), test_sequence_output.float()),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c6d2274b93cd09",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ec1a0c79dbc2a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56536a90ec7c6586",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable anomaly detection\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db497beac7ffd3bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf1dff2a6bc96474",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13741888 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\okan2\\anaconda3\\envs\\animationSVG\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from AnimationTransformer import AnimationTransformer\n",
    "\n",
    "model = AnimationTransformer(\n",
    "    dim_model=FEATURE_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_encoder_layers=NUM_ENCODER_LAYERS,\n",
    "    num_decoder_layers=NUM_DECODER_LAYERS,\n",
    "    dropout_p=DROPOUT,\n",
    "    use_positional_encoder=True\n",
    ").to(device)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "total_param = sum(p.numel() for p in model.parameters())\n",
    "print(f\"The model has {total_param} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e011ea2a897aa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "504fb525334cb368",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\okan2\\anaconda3\\envs\\animationSVG\\lib\\site-packages\\torch\\nn\\functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 1: Time per Batch  1.37s | Total expected  1.85 min | Remaining  1.82 min \n",
      ">> 10: Time per Batch  0.85s | Total expected  1.15 min | Remaining  1.01 min \n",
      ">> 20: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.84 min \n",
      ">> 30: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.56 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 29.1618\n",
      "Validation loss: 21.0042\n",
      "\n",
      "------------------------- Epoch 2 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.18 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.07 min | Remaining  0.54 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.07 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.07 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.79s | Total expected  1.07 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.79s | Total expected  1.07 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.07 min\n",
      "Training loss: 27.4359\n",
      "Validation loss: 20.0076\n",
      "\n",
      "------------------------- Epoch 3 -------------------------\n",
      ">> 1: Time per Batch  0.92s | Total expected  1.25 min | Remaining  1.23 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 26.0720\n",
      "Validation loss: 19.1254\n",
      "\n",
      "------------------------- Epoch 4 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.18 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.56 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.10 min\n",
      "Training loss: 24.7564\n",
      "Validation loss: 18.2824\n",
      "\n",
      "------------------------- Epoch 5 -------------------------\n",
      ">> 1: Time per Batch  0.92s | Total expected  1.24 min | Remaining  1.23 min \n",
      ">> 10: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.99 min \n",
      ">> 20: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.84 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.71 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.56 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.83s | Total expected  1.11 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.83s | Total expected  1.11 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.11 min\n",
      "Training loss: 23.5143\n",
      "Validation loss: 17.4938\n",
      "\n",
      "------------------------- Epoch 6 -------------------------\n",
      ">> 1: Time per Batch  0.92s | Total expected  1.24 min | Remaining  1.22 min \n",
      ">> 10: Time per Batch  0.86s | Total expected  1.16 min | Remaining  1.02 min \n",
      ">> 20: Time per Batch  0.84s | Total expected  1.14 min | Remaining  0.86 min \n",
      ">> 30: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.71 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.12 min\n",
      "Training loss: 22.3701\n",
      "Validation loss: 16.8795\n",
      "\n",
      "------------------------- Epoch 7 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.94 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.07 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.07 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.07 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 21.3856\n",
      "Validation loss: 16.2177\n",
      "\n",
      "------------------------- Epoch 8 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.18 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 20.5470\n",
      "Validation loss: 15.6584\n",
      "\n",
      "------------------------- Epoch 9 -------------------------\n",
      ">> 1: Time per Batch  0.88s | Total expected  1.19 min | Remaining  1.17 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 19.7374\n",
      "Validation loss: 15.1732\n",
      "\n",
      "------------------------- Epoch 10 -------------------------\n",
      ">> 1: Time per Batch  0.88s | Total expected  1.19 min | Remaining  1.17 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 19.0415\n",
      "Validation loss: 14.7639\n",
      "\n",
      "------------------------- Epoch 11 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 18.3856\n",
      "Validation loss: 14.4375\n",
      "\n",
      "------------------------- Epoch 12 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.21 min | Remaining  1.20 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.98 min \n",
      ">> 20: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.83 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.56 min \n",
      ">> 50: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.84s | Total expected  1.14 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.14 min\n",
      "Training loss: 17.8691\n",
      "Validation loss: 14.0260\n",
      "\n",
      "------------------------- Epoch 13 -------------------------\n",
      ">> 1: Time per Batch  0.92s | Total expected  1.24 min | Remaining  1.23 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.99 min \n",
      ">> 20: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.84 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.71 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.12 min\n",
      "Training loss: 17.2918\n",
      "Validation loss: 13.7412\n",
      "\n",
      "------------------------- Epoch 14 -------------------------\n",
      ">> 1: Time per Batch  0.91s | Total expected  1.23 min | Remaining  1.21 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.99 min \n",
      ">> 20: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.85 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.71 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.12 min\n",
      "Training loss: 16.9028\n",
      "Validation loss: 13.4712\n",
      "\n",
      "------------------------- Epoch 15 -------------------------\n",
      ">> 1: Time per Batch  1.00s | Total expected  1.35 min | Remaining  1.33 min \n",
      ">> 10: Time per Batch  0.85s | Total expected  1.14 min | Remaining  1.00 min \n",
      ">> 20: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.85 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.70 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.12 min\n",
      "Training loss: 16.4918\n",
      "Validation loss: 13.2398\n",
      "\n",
      "------------------------- Epoch 16 -------------------------\n",
      ">> 1: Time per Batch  0.91s | Total expected  1.23 min | Remaining  1.22 min \n",
      ">> 10: Time per Batch  0.84s | Total expected  1.14 min | Remaining  1.00 min \n",
      ">> 20: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.85 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.71 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.12 min\n",
      "Training loss: 16.1370\n",
      "Validation loss: 13.0406\n",
      "\n",
      "------------------------- Epoch 17 -------------------------\n",
      ">> 1: Time per Batch  0.94s | Total expected  1.27 min | Remaining  1.25 min \n",
      ">> 10: Time per Batch  0.84s | Total expected  1.14 min | Remaining  1.00 min \n",
      ">> 20: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.85 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.71 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.13 min\n",
      "Training loss: 15.8325\n",
      "Validation loss: 12.9020\n",
      "\n",
      "------------------------- Epoch 18 -------------------------\n",
      ">> 1: Time per Batch  0.93s | Total expected  1.26 min | Remaining  1.24 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.99 min \n",
      ">> 20: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.85 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.71 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.12 min\n",
      "Training loss: 15.5776\n",
      "Validation loss: 12.7412\n",
      "\n",
      "------------------------- Epoch 19 -------------------------\n",
      ">> 1: Time per Batch  0.92s | Total expected  1.25 min | Remaining  1.23 min \n",
      ">> 10: Time per Batch  0.85s | Total expected  1.14 min | Remaining  1.00 min \n",
      ">> 20: Time per Batch  0.85s | Total expected  1.14 min | Remaining  0.86 min \n",
      ">> 30: Time per Batch  0.84s | Total expected  1.14 min | Remaining  0.72 min \n",
      ">> 40: Time per Batch  0.84s | Total expected  1.14 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.84s | Total expected  1.13 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.13 min\n",
      "Training loss: 15.3703\n",
      "Validation loss: 12.6160\n",
      "\n",
      "------------------------- Epoch 20 -------------------------\n",
      ">> 1: Time per Batch  0.92s | Total expected  1.24 min | Remaining  1.22 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.98 min \n",
      ">> 20: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.84 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.70 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.57 min \n",
      ">> 50: Time per Batch  0.83s | Total expected  1.11 min | Remaining  0.43 min \n",
      ">> 60: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.11 min\n",
      "Training loss: 15.1536\n",
      "Validation loss: 12.5313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from AnimationTransformer import fit\n",
    "\n",
    "train_loss_list, validation_loss_list = fit(model,\n",
    "                                            optimizer,\n",
    "                                            loss_function,\n",
    "                                            train_dataloader,\n",
    "                                            val_dataloader,\n",
    "                                            epochs=20,\n",
    "                                            device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c920a75e5f59950",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n",
      ">> 1: Time per Batch  0.96s | Total expected  1.29 min | Remaining  1.27 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 15.0234\n",
      "Validation loss: 12.4377\n",
      "\n",
      "------------------------- Epoch 2 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.94 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.8597\n",
      "Validation loss: 12.3704\n",
      "\n",
      "------------------------- Epoch 3 -------------------------\n",
      ">> 1: Time per Batch  0.91s | Total expected  1.22 min | Remaining  1.21 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.7227\n",
      "Validation loss: 12.3377\n",
      "\n",
      "------------------------- Epoch 4 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.22 min | Remaining  1.21 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.83 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.6368\n",
      "Validation loss: 12.2841\n",
      "\n",
      "------------------------- Epoch 5 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.21 min | Remaining  1.20 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.98 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.83 min \n",
      ">> 30: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.5345\n",
      "Validation loss: 12.2274\n",
      "\n",
      "------------------------- Epoch 6 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.83 min \n",
      ">> 30: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.70 min \n",
      ">> 40: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.56 min \n",
      ">> 50: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.4406\n",
      "Validation loss: 12.2310\n",
      "\n",
      "------------------------- Epoch 7 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.4197\n",
      "Validation loss: 12.1914\n",
      "\n",
      "------------------------- Epoch 8 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.3725\n",
      "Validation loss: 12.1949\n",
      "\n",
      "------------------------- Epoch 9 -------------------------\n",
      ">> 1: Time per Batch  0.88s | Total expected  1.19 min | Remaining  1.17 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.3490\n",
      "Validation loss: 12.1752\n",
      "\n",
      "------------------------- Epoch 10 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.22 min | Remaining  1.20 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.2938\n",
      "Validation loss: 12.2052\n",
      "\n",
      "------------------------- Epoch 11 -------------------------\n",
      ">> 1: Time per Batch  0.88s | Total expected  1.19 min | Remaining  1.17 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.2958\n",
      "Validation loss: 12.2235\n",
      "\n",
      "------------------------- Epoch 12 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.18 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.2744\n",
      "Validation loss: 12.1835\n",
      "\n",
      "------------------------- Epoch 13 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.2398\n",
      "Validation loss: 12.1784\n",
      "\n",
      "------------------------- Epoch 14 -------------------------\n",
      ">> 1: Time per Batch  0.91s | Total expected  1.22 min | Remaining  1.21 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.2293\n",
      "Validation loss: 12.1311\n",
      "\n",
      "------------------------- Epoch 15 -------------------------\n",
      ">> 1: Time per Batch  0.93s | Total expected  1.26 min | Remaining  1.24 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.98 min \n",
      ">> 20: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.83 min \n",
      ">> 30: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.56 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.10 min\n",
      "Training loss: 14.2292\n",
      "Validation loss: 12.1630\n",
      "\n",
      "------------------------- Epoch 16 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.21 min | Remaining  1.20 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.83 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.2560\n",
      "Validation loss: 12.1747\n",
      "\n",
      "------------------------- Epoch 17 -------------------------\n",
      ">> 1: Time per Batch  0.87s | Total expected  1.18 min | Remaining  1.17 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.1780\n",
      "Validation loss: 12.1726\n",
      "\n",
      "------------------------- Epoch 18 -------------------------\n",
      ">> 1: Time per Batch  0.91s | Total expected  1.22 min | Remaining  1.21 min \n",
      ">> 10: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.2320\n",
      "Validation loss: 12.1953\n",
      "\n",
      "------------------------- Epoch 19 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.21 min | Remaining  1.20 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.2338\n",
      "Validation loss: 12.1920\n",
      "\n",
      "------------------------- Epoch 20 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.20 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.2314\n",
      "Validation loss: 12.2000\n",
      "\n",
      "------------------------- Epoch 21 -------------------------\n",
      ">> 1: Time per Batch  0.88s | Total expected  1.19 min | Remaining  1.17 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.96 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.41 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.2286\n",
      "Validation loss: 12.2810\n",
      "\n",
      "------------------------- Epoch 22 -------------------------\n",
      ">> 1: Time per Batch  0.91s | Total expected  1.23 min | Remaining  1.22 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.2224\n",
      "Validation loss: 12.1976\n",
      "\n",
      "------------------------- Epoch 23 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.21 min | Remaining  1.20 min \n",
      ">> 10: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.95 min \n",
      ">> 20: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.81 min \n",
      ">> 30: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.1956\n",
      "Validation loss: 12.2037\n",
      "\n",
      "------------------------- Epoch 24 -------------------------\n",
      ">> 1: Time per Batch  0.91s | Total expected  1.23 min | Remaining  1.21 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.98 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.83 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.2258\n",
      "Validation loss: 12.2027\n",
      "\n",
      "------------------------- Epoch 25 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.22 min | Remaining  1.20 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.2093\n",
      "Validation loss: 12.2311\n",
      "\n",
      "------------------------- Epoch 26 -------------------------\n",
      ">> 1: Time per Batch  0.91s | Total expected  1.23 min | Remaining  1.21 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.99 min \n",
      ">> 20: Time per Batch  0.84s | Total expected  1.14 min | Remaining  0.85 min \n",
      ">> 30: Time per Batch  0.83s | Total expected  1.12 min | Remaining  0.71 min \n",
      ">> 40: Time per Batch  0.83s | Total expected  1.11 min | Remaining  0.56 min \n",
      ">> 50: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.29 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.10 min\n",
      "Training loss: 14.1493\n",
      "Validation loss: 12.2388\n",
      "\n",
      "------------------------- Epoch 27 -------------------------\n",
      ">> 1: Time per Batch  0.90s | Total expected  1.21 min | Remaining  1.20 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.68 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.80s | Total expected  1.08 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.08 min\n",
      "Training loss: 14.1928\n",
      "Validation loss: 12.2036\n",
      "\n",
      "------------------------- Epoch 28 -------------------------\n",
      ">> 1: Time per Batch  0.89s | Total expected  1.21 min | Remaining  1.19 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.11 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.1962\n",
      "Validation loss: 12.1764\n",
      "\n",
      "------------------------- Epoch 29 -------------------------\n",
      ">> 1: Time per Batch  0.92s | Total expected  1.24 min | Remaining  1.22 min \n",
      ">> 10: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.97 min \n",
      ">> 20: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.82 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.80s | Total expected  1.09 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.09 min\n",
      "Training loss: 14.2226\n",
      "Validation loss: 12.2086\n",
      "\n",
      "------------------------- Epoch 30 -------------------------\n",
      ">> 1: Time per Batch  0.94s | Total expected  1.26 min | Remaining  1.25 min \n",
      ">> 10: Time per Batch  0.83s | Total expected  1.13 min | Remaining  0.99 min \n",
      ">> 20: Time per Batch  0.82s | Total expected  1.10 min | Remaining  0.83 min \n",
      ">> 30: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.69 min \n",
      ">> 40: Time per Batch  0.81s | Total expected  1.09 min | Remaining  0.55 min \n",
      ">> 50: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.42 min \n",
      ">> 60: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.28 min \n",
      ">> 70: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.15 min \n",
      ">> 80: Time per Batch  0.81s | Total expected  1.10 min | Remaining  0.01 min \n",
      ">> Epoch time: 1.10 min\n",
      "Training loss: 14.2152\n",
      "Validation loss: 12.1917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the number of additional epochs you want to train for\n",
    "additional_epochs = 30\n",
    "\n",
    "# Continue training the model for more epochs\n",
    "new_train_loss, new_validation_loss = fit(model,\n",
    "                                          optimizer,\n",
    "                                          loss_function,\n",
    "                                          train_dataloader,\n",
    "                                          val_dataloader,\n",
    "                                          epochs=additional_epochs,\n",
    "                                          device=device)\n",
    "\n",
    "# Extend the original loss lists with the new loss values\n",
    "train_loss_list.extend(new_train_loss)\n",
    "validation_loss_list.extend(new_validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f853ce1cf82a124",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      " 29,1618; 27,4359; 26,0720; 24,7564; 23,5143; 22,3701; 21,3856; 20,5470; 19,7374; 19,0415; 18,3856; 17,8691; 17,2918; 16,9028; 16,4918; 16,1370; 15,8325; 15,5776; 15,3703; 15,1536; 15,0234; 14,8597; 14,7227; 14,6368; 14,5345; 14,4406; 14,4197; 14,3725; 14,3490; 14,2938; 14,2958; 14,2744; 14,2398; 14,2293; 14,2292; 14,2560; 14,1780; 14,2320; 14,2338; 14,2314; 14,2286; 14,2224; 14,1956; 14,2258; 14,2093; 14,1493; 14,1928; 14,1962; 14,2226; 14,2152\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\\n\", \"; \".join([str(f\"{loss:.4f}\").replace('.', ',') for loss in train_loss_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d35cb0098fe9feb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      " 21,0042; 20,0076; 19,1254; 18,2824; 17,4938; 16,8795; 16,2177; 15,6584; 15,1732; 14,7639; 14,4375; 14,0260; 13,7412; 13,4712; 13,2398; 13,0406; 12,9020; 12,7412; 12,6160; 12,5313; 12,4377; 12,3704; 12,3377; 12,2841; 12,2274; 12,2310; 12,1914; 12,1949; 12,1752; 12,2052; 12,2235; 12,1835; 12,1784; 12,1311; 12,1630; 12,1747; 12,1726; 12,1953; 12,1920; 12,2000; 12,2810; 12,1976; 12,2037; 12,2027; 12,2311; 12,2388; 12,2036; 12,1764; 12,2086; 12,1917\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation\\n\", \"; \".join([str(f\"{loss:.4f}\").replace('.', ',') for loss in validation_loss_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1c6564934a7af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training and Validation Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89297cea9ea4a9c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_list, label='Training Loss')\n",
    "plt.plot(validation_loss_list, label='Validation Loss')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2098b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/models/animation_transformer.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbeac949784565",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8452421fbb912",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sequences with long input\n",
    "test_sequence_input[30, :, 0] # 50, 10, 220, 222, 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e04b3d1425a49",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check sequence length / embedding\n",
    "print(test_sequence_output[20, :, -26:])\n",
    "print(test_sequence_input [20, :, -26:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a328c640894ee5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a tensor of zeros with 270 elements\n",
    "sos_token = torch.zeros(282)\n",
    "# Set the value at the 256 index to 1\n",
    "sos_token[256] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1275cdf2526d3d2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from AnimationTransformer import predict\n",
    "\n",
    "result = predict(model, test_sequence_input[10], sos_token=sos_token, device=device, max_length=10, eos_scaling=0.01)\n",
    "print(result, result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = result.cpu()\n",
    "model_parameters = result[:,-26:].detach().numpy()\n",
    "print(model_parameters, model_parameters.shape)\n",
    "\n",
    "model_parameters = pd.DataFrame(model_parameters)\n",
    "model_parameters[\"model_output\"] = model_parameters.apply(lambda row: row.tolist(), axis=1)\n",
    "\n",
    "# Apply the custom function to the \"model_output\" column\n",
    "model_parameters = model_parameters[['model_output']]\n",
    "\n",
    "model_parameters[\"animation_id\"] = range(0, len(model_parameters))\n",
    "print(model_parameters, model_parameters.shape)\n",
    "from src.postprocessing.postprocessing import animate_logo\n",
    "\n",
    "animate_logo(model_parameters, \"data/1_inserted_animation_id/logo_104.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785899ffda9c61f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac116ba60f873a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from AnimationTransformer import validation_loop, train_loop\n",
    "import optuna\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    num_encoder_layers = trial.suggest_categorical('num_encoder_layers', [2, 4, 6, 8])\n",
    "    num_decoder_layers = trial.suggest_categorical('num_decoder_layers', [4, 6, 8, 10])\n",
    "    # batch_size = trial.suggest_categorical('batch_size', [64])\n",
    "    num_heads = trial.suggest_categorical('num_heads', [ 3, 6, 47, 94])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.2)\n",
    "    use_positional_encoder = trial.suggest_categorical('pos_encoder_max_len', [True, False])\n",
    "    \n",
    "    print(f'Parameters selected')\n",
    "    print(f'num_encoder_layers; num_decoder_layers; learning_rate; num_heads; use_positional_encoder; dropout')\n",
    "    print(f'{num_encoder_layers}; {num_decoder_layers}; {learning_rate}; {num_heads}; {use_positional_encoder}; {dropout}'.replace('.', ','))\n",
    "    \n",
    "    # Instantiate the model with suggested hyperparameters\n",
    "    model = AnimationTransformer(\n",
    "        dim_model=FEATURE_DIM,\n",
    "        num_heads=num_heads,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        num_decoder_layers=num_decoder_layers,\n",
    "        dropout_p=dropout,\n",
    "        use_positional_encoder=use_positional_encoder\n",
    "    ).to(device)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_loss_list, validation_loss_list = [], []\n",
    "\n",
    "    validation_loss = -1\n",
    "    # Training loop with early stopping, validation, etc.\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        print(f' =========== EPOCH {epoch} ===========')\n",
    "        \n",
    "        train_loss = train_loop(model, optimizer, loss_function, train_dataloader, device)\n",
    "        train_loss_list += [train_loss]\n",
    "\n",
    "        validation_loss = validation_loop(model, loss_function, val_dataloader, device)\n",
    "        validation_loss_list += [validation_loss]\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}')\n",
    "        \n",
    "        # Report the validation loss to Optuna\n",
    "        trial.report(validation_loss, epoch)\n",
    "        \n",
    "        # Implement early stopping logic\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    print(f'Best validation loss: {validation_loss}')\n",
    "    print(f'num_encoder_layers; num_decoder_layers; learning_rate; num_heads; use_positional_encoder; dropout;')\n",
    "    print(f'{num_encoder_layers}; {num_decoder_layers}; {learning_rate:.8f}; {num_heads}; {use_positional_encoder}; {dropout:.8f}; Validation; '.replace('.', ','),\n",
    "          \"; \".join([str(f\"{loss:.4f}\").replace('.', ',') for loss in validation_loss_list]))\n",
    "    print(f' ; ; ; ; ; Train; ',\n",
    "          \"; \".join([str(f\"{loss:.4f}\").replace('.', ',') for loss in train_loss_list]))\n",
    "    \n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec6f9ac58486db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Used:\n",
    "- pick_and_animate_from_8     First Run\n",
    "- pick_and_animate_from_8_v3  First Main Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c795e29038042",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name='FinalTransformer', # IMPORTANT: Chance Name when new Dataset\n",
    "    storage='sqlite:///animate_svg_optuna.db',\n",
    "    load_if_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f41c46488c115",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#study = optuna.create_study(direction='minimize')\n",
    "my_study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68b3288e88b82c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = my_study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4454b71fe58709",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "plot_optimization_history(my_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af745d741c9f91e8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_param_importances(my_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9536888eb5d9ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_slice\n",
    "\n",
    "plot_slice(my_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b93522b8685dc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_timeline\n",
    "\n",
    "plot_timeline(my_study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed50888",
   "metadata": {},
   "source": [
    "## Reinforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e109bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REWARDFUNCTIONTEST\n",
    "\n",
    "from transformer_for_reward_function import RewardTransformer\n",
    "\n",
    "inputdata = torch.cat([train_sequence_output, test_sequence_output], dim=0).to(device)\n",
    "\n",
    "reward = RewardTransformer(\n",
    "            dim_model=282,\n",
    "            num_heads=6,\n",
    "            num_encoder_layers=8,\n",
    "            num_decoder_layers=8,\n",
    "            dropout_p=0.1,\n",
    "            num_tokens=inputdata[0:1,:,:].shape[1]).to(device)\n",
    "        \n",
    "reward.load_state_dict(torch.load(\"data/models/reward_function_mode_state_dict_4.pth\"))\n",
    "reward.eval()\n",
    "pred = reward(inputdata[1:2,:,:], inputdata[2:3,:,:])\n",
    "print(pred, pred.shape)\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "print(spaces.Box(low=0, high=1, shape=(100, 10), dtype=int).sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "from transformer_for_reward_function import RewardTransformer\n",
    "\n",
    "test = torch.tensor(0)\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self, startingState : torch.tensor):\n",
    "        super(CustomEnv, self).__init__()\n",
    "\n",
    "        # Define your action and observation space\n",
    "        self.action_space = spaces.Discrete(10)\n",
    "\n",
    "        # Example: 6-dimensional observation space represented by a Box\n",
    "        self.observation_space = startingState.to(device)\n",
    "\n",
    "        self.rewardList = []\n",
    "\n",
    "        # Define any other environment parameters\n",
    "        self.max_steps = 1\n",
    "        self.current_step = 0\n",
    "\n",
    "        self.reward = RewardTransformer(\n",
    "            dim_model=282,\n",
    "            num_heads=6,\n",
    "            num_encoder_layers=8,\n",
    "            num_decoder_layers=8,\n",
    "            dropout_p=0.1,\n",
    "            num_tokens=startingState.shape[1]).to(device)\n",
    "        \n",
    "        self.reward.load_state_dict(torch.load(\"data/models/reward_function_mode_state_dict_4.pth\"))\n",
    "        \n",
    "\n",
    "    def reset(self, startingState : torch.tensor):\n",
    "        # Reset the environment to its initial state\n",
    "        self.current_step = 0\n",
    "        self.observation_space = startingState\n",
    "        # Return the initial observation\n",
    "        return self.observation_space.to(device)\n",
    "\n",
    "    def step(self, action, reward):\n",
    "        ##### STATE = APPLY ACTION TO OBSERVATION #####\n",
    "        state = torch.squeeze(action)\n",
    "        \n",
    "        self.rewardList.append(reward)\n",
    "        \n",
    "        done = self.current_step >= self.max_steps\n",
    "        self.current_step += 1\n",
    "        return state.to(device), reward, done\n",
    "\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, input : torch.tensor, env : CustomEnv):\n",
    "\n",
    "        self.input = input\n",
    "        self.X = input[0].to(device)\n",
    "        #self.y = self.randomAnimation(self.X).to(device)\n",
    "\n",
    "        self.currentLogo = 0\n",
    "\n",
    "        self.epsilon = 0.8\n",
    "\n",
    "        self.model = AnimationTransformer(\n",
    "            dim_model=FEATURE_DIM,\n",
    "            num_heads=NUM_HEADS,\n",
    "            num_encoder_layers=NUM_ENCODER_LAYERS,\n",
    "            num_decoder_layers=NUM_DECODER_LAYERS,\n",
    "            dropout_p=DROPOUT,\n",
    "            use_positional_encoder=True\n",
    "        ).to(device)\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        self.loss_fn = CustomEmbeddingSliceLoss()\n",
    "\n",
    "        self.total_loss = 0\n",
    "\n",
    "        self.env = env\n",
    "    \n",
    "    def randomAnimation(self, t : torch.tensor):\n",
    "        #print(t.shape)\n",
    "        for i in range(t.shape[0]):\n",
    "            for j in range(t.shape[1]):\n",
    "                type = random.randint(0,10)\n",
    "                if t[i,j,256+type] != .100:\n",
    "                    t[i,j,256+type] = 1\n",
    "                    for d in range (266, 282):\n",
    "                        t[i,j,d] = random.random()\n",
    "        return t.to(device)\n",
    "    \n",
    "    def trainStep(self):\n",
    "        print(\"X: \",self.X, self.X.shape)\n",
    "        # Create a tensor of zeros with 270 elements\n",
    "        sos_token = torch.zeros(282).to(device)\n",
    "        # Set the value at the 256 index to 1\n",
    "        sos_token[256] = 1\n",
    "        \n",
    "        self.y = predict(self.model, self.X, sos_token=sos_token, device=device, max_length=10, eos_scaling=0.01, backpropagate=True, showResult=False).to(device)\n",
    "        \n",
    "        return torch.unsqueeze(self.y, dim=0).to(device)\n",
    "    \n",
    "    def chooseAction(self, pred : torch.tensor):\n",
    "        \n",
    "        print(\"choose action for:\", pred, pred.shape, type(pred))\n",
    "\n",
    "        possibleSteps = []\n",
    "        possibleStepsRewards = []\n",
    "\n",
    "        for path in range(pred.shape[1]):\n",
    "            for step in range(10):\n",
    "                next = pred \n",
    "                t = np.zeros(10, dtype=int)\n",
    "                t[step] = 1\n",
    "                #print(next[:, path, :], next[:, path, 256:266])\n",
    "                next[:, path, 256:266] = torch.tensor(t)\n",
    "                reward = self.env.reward(pred, next)[0,0,0]\n",
    "                possibleSteps.append(next.to(device))\n",
    "                possibleStepsRewards.append(reward.item())\n",
    "\n",
    "        q = random.random()\n",
    "\n",
    "        if q > self.epsilon:\n",
    "            print(\"explore\")\n",
    "            idx = random.randint(0,len(possibleSteps)-1)\n",
    "        else:\n",
    "            print(\"exploit\")\n",
    "            idx = possibleStepsRewards.index(max(possibleStepsRewards))\n",
    "\n",
    "        action = possibleSteps[idx]\n",
    "        reward = possibleStepsRewards[idx]\n",
    "        print(\"action\", action, action.shape, \"reward\", reward)\n",
    "        return action, reward\n",
    "\n",
    "    def nextLogo(self):\n",
    "        self.X = self.input[self.currentLogo+1].to(device)\n",
    "        #self.y = self.randomAnimation(self.X).to(device)\n",
    "\n",
    "        self.currentLogo = self.currentLogo+1\n",
    "    \n",
    "\n",
    "\n",
    "def reinforce():\n",
    "\n",
    "    env = CustomEnv(inputdata[0:1, :, :])\n",
    "    agent = Agent(inputdata, env)\n",
    "\n",
    "    totalReward = 0\n",
    "    for i in range(1, inputdata.shape[0]):\n",
    "        \n",
    "        print(i)\n",
    "        observation = env.reset(inputdata[i-1:i, :, :])\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "                \n",
    "            current = agent.trainStep()\n",
    "            action, reward = agent.chooseAction(current)\n",
    "\n",
    "            state, reward, done = env.step(action, reward)\n",
    "            print(state.shape)\n",
    "            agent.X = state\n",
    "            totalReward += reward\n",
    "\n",
    "        agent.nextLogo()\n",
    "\n",
    "inputdata = torch.cat([train_sequence_output, test_sequence_output], dim=0).to(device)\n",
    "#print(inputdata, inputdata.shape)\n",
    "reinforce()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eec347",
   "metadata": {},
   "source": [
    "## Animation Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c0bf1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
