{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset,random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir(\"./../.\")\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2162ab984c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the output 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "torch.__version__\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okan2\\AppData\\Local\\Temp\\ipykernel_10012\\1844141353.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_output2['label2'] = filtered_output2['label'].replace(mapping_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>animation_id</th>\n",
       "      <th>model_output</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, -1.0, -1.0, -1.0, 0.4205715...</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>21</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.4...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file  animation_id  \\\n",
       "436   logo_0_animation_0             0   \n",
       "439   logo_0_animation_0             1   \n",
       "438   logo_0_animation_0             3   \n",
       "437   logo_0_animation_0             4   \n",
       "435   logo_0_animation_0             5   \n",
       "..                   ...           ...   \n",
       "892  logo_99_animation_0            21   \n",
       "811  logo_99_animation_0            22   \n",
       "891  logo_99_animation_0            22   \n",
       "810  logo_99_animation_0            23   \n",
       "890  logo_99_animation_0            23   \n",
       "\n",
       "                                          model_output      label  label2  \n",
       "436  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...       Good     5.0  \n",
       "439  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0  \n",
       "438  [0, 0, 0, 0, 0, 1, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0  \n",
       "437  [0, 0, 1, 0, 0, 0, -1.0, -1.0, -1.0, 0.4205715...       Good     5.0  \n",
       "435  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0  \n",
       "..                                                 ...        ...     ...  \n",
       "892  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.4...  Very Good     6.0  \n",
       "811  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...  Very Good     6.0  \n",
       "891  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...  Very Good     6.0  \n",
       "810  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....  Very Good     6.0  \n",
       "890  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....  Very Good     6.0  \n",
       "\n",
       "[907 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50., dtype=torch.float64)\n",
      "torch.Size([359, 6, 268])\n",
      "tensor([[[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/surrogate_model/animation_label.pkl\", \"rb\") as f:\n",
    "    surrogate2 = pickle.load(f)\n",
    "\n",
    "#Filter with only good or very good ratings\n",
    "#filtered_output = surrogate[surrogate)][['label'].isin(['Good','Very Good'][\"file\",\"animation_id\",\"model_output\",\"label\"]]\n",
    "filtered_output2 = surrogate2[[\"file\",\"animation_id\",\"model_output\",\"label\"]]\n",
    "\n",
    "# dictionary for mapping\n",
    "\n",
    "mapping_dict = {\"Very Good\": 6, \"Good\": 5, \"Bad\": 4,\"Okay\":3, \"Very Bad\": 2, \"no_rating\": 1}\n",
    "\n",
    "# Create another column changing the label into ints\n",
    "\n",
    "filtered_output2['label2'] = filtered_output2['label'].replace(mapping_dict)\n",
    "\n",
    "\n",
    "# get the names of unique logos by splitting with animation number\n",
    "logos = filtered_output2[\"file\"].str.split(\"_animation\").str[0].unique()\n",
    "\n",
    "#print(logos)\n",
    "\n",
    "# create a data frame for the collected best animations\n",
    "bestoutput2 = pd.DataFrame()\n",
    "\n",
    "# go through each logo to find the best animation\n",
    "for logo in logos:\n",
    "\n",
    "    # make a data frame that contains all the animations of one logo\n",
    "    temp = filtered_output2[filtered_output2[\"file\"].str.contains(logo)]\n",
    "\n",
    "    #display(temp)\n",
    "\n",
    "    # create a sum \n",
    "    mean_by_label = temp.groupby('file')['label2'].mean().reset_index()\n",
    "\n",
    "    #print(mean_by_label)\n",
    "\n",
    "    bestlogo = mean_by_label.loc[mean_by_label['label2'].idxmax()]\n",
    "\n",
    "    #print(bestlogo)\n",
    "\n",
    "    # get all the animated paths with the best animation of the logo\n",
    "    best_animations2 = temp[temp[\"file\"]==bestlogo[\"file\"]]\n",
    "\n",
    "    # add to the file\n",
    "    bestoutput2 = pd.concat([bestoutput2,best_animations2],axis=0, ignore_index=True)\n",
    "bestoutput2 = bestoutput2.sort_values(by=['file','animation_id'])\n",
    "display(bestoutput2)\n",
    "\n",
    "filenames = bestoutput2[\"file\"].unique()\n",
    "list = []\n",
    "for name in filenames:\n",
    "    seq = bestoutput2[bestoutput2[\"file\"]==name]\n",
    "    seq = seq[\"model_output\"]\n",
    "    seq = pd.DataFrame(bestoutput2[\"model_output\"].to_list(), columns=[\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"a7\",\"a8\",\"a9\",\"a10\",\"a11\",\"a12\"])\n",
    "    \n",
    "    seq = pd.concat([pd.DataFrame(0, index=seq.index, columns=range(0, 256)), seq], axis=1, ignore_index=True)\n",
    "    \n",
    "    if len(seq) > 4:\n",
    "        seq = seq[:4]\n",
    "\n",
    "    sos = pd.DataFrame([[30]*268])\n",
    "    \n",
    "    eos = pd.DataFrame([[50]*268])\n",
    "\n",
    "    seq = pd.concat([sos, seq, eos], ignore_index=True)\n",
    "    \n",
    "    while len(seq) < 6:\n",
    "           seq = pd.concat([seq, pd.DataFrame([[-100]*268])], ignore_index=True)\n",
    "           \n",
    "    #seq = seq.apply(lambda x: np.array(x).astype(np.float32))\n",
    "    #tokens = []\n",
    "    #for l in seq:\n",
    "    #    tokens.append(torch.tensor(l))\n",
    "\n",
    "    list.append(torch.tensor(seq.values))\n",
    "outTensor2 = torch.stack(list)\n",
    "\n",
    "outTensor2 = outTensor2.to(device)\n",
    "print(outTensor2.max())\n",
    "print(outTensor2.shape)\n",
    "print(outTensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the input tensor with the diltered output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>animation_id</th>\n",
       "      <th>model_output</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, -1.0, -1.0, -1.0, 0.4205715...</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>21</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.4...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file  animation_id  \\\n",
       "436   logo_0_animation_0             0   \n",
       "439   logo_0_animation_0             1   \n",
       "438   logo_0_animation_0             3   \n",
       "437   logo_0_animation_0             4   \n",
       "435   logo_0_animation_0             5   \n",
       "..                   ...           ...   \n",
       "892  logo_99_animation_0            21   \n",
       "811  logo_99_animation_0            22   \n",
       "891  logo_99_animation_0            22   \n",
       "810  logo_99_animation_0            23   \n",
       "890  logo_99_animation_0            23   \n",
       "\n",
       "                                          model_output      label  label2  \\\n",
       "436  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...       Good     5.0   \n",
       "439  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0   \n",
       "438  [0, 0, 0, 0, 0, 1, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0   \n",
       "437  [0, 0, 1, 0, 0, 0, -1.0, -1.0, -1.0, 0.4205715...       Good     5.0   \n",
       "435  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0   \n",
       "..                                                 ...        ...     ...   \n",
       "892  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.4...  Very Good     6.0   \n",
       "811  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...  Very Good     6.0   \n",
       "891  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...  Very Good     6.0   \n",
       "810  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....  Very Good     6.0   \n",
       "890  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....  Very Good     6.0   \n",
       "\n",
       "    filename  \n",
       "436   logo_0  \n",
       "439   logo_0  \n",
       "438   logo_0  \n",
       "437   logo_0  \n",
       "435   logo_0  \n",
       "..       ...  \n",
       "892  logo_99  \n",
       "811  logo_99  \n",
       "891  logo_99  \n",
       "810  logo_99  \n",
       "890  logo_99  \n",
       "\n",
       "[907 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animation_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.763518</td>\n",
       "      <td>-0.982797</td>\n",
       "      <td>-0.446681</td>\n",
       "      <td>1.089468</td>\n",
       "      <td>-0.070563</td>\n",
       "      <td>0.710206</td>\n",
       "      <td>-0.491675</td>\n",
       "      <td>-1.631172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339061</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.195161</td>\n",
       "      <td>-0.046488</td>\n",
       "      <td>-0.492103</td>\n",
       "      <td>-0.605836</td>\n",
       "      <td>-1.282879</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>0.297194</td>\n",
       "      <td>-0.172312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.851117</td>\n",
       "      <td>-1.775123</td>\n",
       "      <td>0.649689</td>\n",
       "      <td>-0.688600</td>\n",
       "      <td>0.216071</td>\n",
       "      <td>0.135211</td>\n",
       "      <td>-1.748761</td>\n",
       "      <td>-1.347670</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.616431</td>\n",
       "      <td>-1.572003</td>\n",
       "      <td>0.242460</td>\n",
       "      <td>0.430259</td>\n",
       "      <td>0.079752</td>\n",
       "      <td>-1.039526</td>\n",
       "      <td>-0.696104</td>\n",
       "      <td>0.090277</td>\n",
       "      <td>-0.228757</td>\n",
       "      <td>0.144372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.291136</td>\n",
       "      <td>-0.928242</td>\n",
       "      <td>0.265542</td>\n",
       "      <td>-0.261439</td>\n",
       "      <td>-0.386160</td>\n",
       "      <td>1.256256</td>\n",
       "      <td>-0.414706</td>\n",
       "      <td>-1.206105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.446020</td>\n",
       "      <td>-1.369758</td>\n",
       "      <td>0.356421</td>\n",
       "      <td>1.456656</td>\n",
       "      <td>0.468766</td>\n",
       "      <td>-1.077724</td>\n",
       "      <td>-0.548627</td>\n",
       "      <td>-0.300660</td>\n",
       "      <td>0.632805</td>\n",
       "      <td>-0.136473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.504446</td>\n",
       "      <td>-0.543099</td>\n",
       "      <td>0.915062</td>\n",
       "      <td>1.293575</td>\n",
       "      <td>-0.849605</td>\n",
       "      <td>1.120387</td>\n",
       "      <td>-0.637641</td>\n",
       "      <td>-1.337280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162753</td>\n",
       "      <td>0.206993</td>\n",
       "      <td>-0.201259</td>\n",
       "      <td>-1.087391</td>\n",
       "      <td>-0.597388</td>\n",
       "      <td>-0.992079</td>\n",
       "      <td>-0.851486</td>\n",
       "      <td>-0.225463</td>\n",
       "      <td>-0.549269</td>\n",
       "      <td>0.088637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>-0.641569</td>\n",
       "      <td>-0.657125</td>\n",
       "      <td>-0.105109</td>\n",
       "      <td>-0.031630</td>\n",
       "      <td>-0.572032</td>\n",
       "      <td>0.912017</td>\n",
       "      <td>-0.569627</td>\n",
       "      <td>-1.573482</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.079276</td>\n",
       "      <td>0.285482</td>\n",
       "      <td>1.532865</td>\n",
       "      <td>-0.375210</td>\n",
       "      <td>-0.249130</td>\n",
       "      <td>-0.551393</td>\n",
       "      <td>-1.024246</td>\n",
       "      <td>0.623726</td>\n",
       "      <td>-1.073305</td>\n",
       "      <td>0.166613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>21</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>0.729620</td>\n",
       "      <td>-1.035586</td>\n",
       "      <td>0.390709</td>\n",
       "      <td>1.910684</td>\n",
       "      <td>-0.489203</td>\n",
       "      <td>2.197111</td>\n",
       "      <td>0.424709</td>\n",
       "      <td>-0.389426</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130544</td>\n",
       "      <td>-1.892641</td>\n",
       "      <td>-0.690288</td>\n",
       "      <td>1.371062</td>\n",
       "      <td>0.718980</td>\n",
       "      <td>-0.827454</td>\n",
       "      <td>-0.557172</td>\n",
       "      <td>0.235162</td>\n",
       "      <td>0.523978</td>\n",
       "      <td>-0.592003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>22</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.147938</td>\n",
       "      <td>-0.799806</td>\n",
       "      <td>0.664411</td>\n",
       "      <td>1.610482</td>\n",
       "      <td>-0.612273</td>\n",
       "      <td>1.194499</td>\n",
       "      <td>0.076532</td>\n",
       "      <td>-0.662109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415811</td>\n",
       "      <td>-1.569571</td>\n",
       "      <td>-0.424470</td>\n",
       "      <td>0.518902</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>-1.283986</td>\n",
       "      <td>-0.463894</td>\n",
       "      <td>0.319661</td>\n",
       "      <td>0.785325</td>\n",
       "      <td>-0.294870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>22</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.147938</td>\n",
       "      <td>-0.799806</td>\n",
       "      <td>0.664411</td>\n",
       "      <td>1.610482</td>\n",
       "      <td>-0.612273</td>\n",
       "      <td>1.194499</td>\n",
       "      <td>0.076532</td>\n",
       "      <td>-0.662109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415811</td>\n",
       "      <td>-1.569571</td>\n",
       "      <td>-0.424470</td>\n",
       "      <td>0.518902</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>-1.283986</td>\n",
       "      <td>-0.463894</td>\n",
       "      <td>0.319661</td>\n",
       "      <td>0.785325</td>\n",
       "      <td>-0.294870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>23</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.645128</td>\n",
       "      <td>-1.911424</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>0.850210</td>\n",
       "      <td>0.554424</td>\n",
       "      <td>1.578238</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.704658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883759</td>\n",
       "      <td>-2.000007</td>\n",
       "      <td>-0.517095</td>\n",
       "      <td>2.213172</td>\n",
       "      <td>0.733567</td>\n",
       "      <td>-0.577074</td>\n",
       "      <td>-0.710312</td>\n",
       "      <td>-0.591997</td>\n",
       "      <td>0.836300</td>\n",
       "      <td>-0.720247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>23</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.645128</td>\n",
       "      <td>-1.911424</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>0.850210</td>\n",
       "      <td>0.554424</td>\n",
       "      <td>1.578238</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.704658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883759</td>\n",
       "      <td>-2.000007</td>\n",
       "      <td>-0.517095</td>\n",
       "      <td>2.213172</td>\n",
       "      <td>0.733567</td>\n",
       "      <td>-0.577074</td>\n",
       "      <td>-0.710312</td>\n",
       "      <td>-0.591997</td>\n",
       "      <td>0.836300</td>\n",
       "      <td>-0.720247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     animation_id filename         0         1         2         3         4  \\\n",
       "0               0   logo_0  0.763518 -0.982797 -0.446681  1.089468 -0.070563   \n",
       "1               1   logo_0  0.851117 -1.775123  0.649689 -0.688600  0.216071   \n",
       "2               3   logo_0  0.291136 -0.928242  0.265542 -0.261439 -0.386160   \n",
       "3               4   logo_0  0.504446 -0.543099  0.915062  1.293575 -0.849605   \n",
       "4               5   logo_0 -0.641569 -0.657125 -0.105109 -0.031630 -0.572032   \n",
       "..            ...      ...       ...       ...       ...       ...       ...   \n",
       "902            21  logo_99  0.729620 -1.035586  0.390709  1.910684 -0.489203   \n",
       "903            22  logo_99  1.147938 -0.799806  0.664411  1.610482 -0.612273   \n",
       "904            22  logo_99  1.147938 -0.799806  0.664411  1.610482 -0.612273   \n",
       "905            23  logo_99  1.645128 -1.911424  0.806118  0.850210  0.554424   \n",
       "906            23  logo_99  1.645128 -1.911424  0.806118  0.850210  0.554424   \n",
       "\n",
       "            5         6         7  ...       246       247       248  \\\n",
       "0    0.710206 -0.491675 -1.631172  ...  0.339061  0.022934  0.195161   \n",
       "1    0.135211 -1.748761 -1.347670  ... -1.616431 -1.572003  0.242460   \n",
       "2    1.256256 -0.414706 -1.206105  ... -0.446020 -1.369758  0.356421   \n",
       "3    1.120387 -0.637641 -1.337280  ...  0.162753  0.206993 -0.201259   \n",
       "4    0.912017 -0.569627 -1.573482  ... -1.079276  0.285482  1.532865   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "902  2.197111  0.424709 -0.389426  ...  1.130544 -1.892641 -0.690288   \n",
       "903  1.194499  0.076532 -0.662109  ...  0.415811 -1.569571 -0.424470   \n",
       "904  1.194499  0.076532 -0.662109  ...  0.415811 -1.569571 -0.424470   \n",
       "905  1.578238 -0.722733 -0.704658  ...  0.883759 -2.000007 -0.517095   \n",
       "906  1.578238 -0.722733 -0.704658  ...  0.883759 -2.000007 -0.517095   \n",
       "\n",
       "          249       250       251       252       253       254       255  \n",
       "0   -0.046488 -0.492103 -0.605836 -1.282879  0.613195  0.297194 -0.172312  \n",
       "1    0.430259  0.079752 -1.039526 -0.696104  0.090277 -0.228757  0.144372  \n",
       "2    1.456656  0.468766 -1.077724 -0.548627 -0.300660  0.632805 -0.136473  \n",
       "3   -1.087391 -0.597388 -0.992079 -0.851486 -0.225463 -0.549269  0.088637  \n",
       "4   -0.375210 -0.249130 -0.551393 -1.024246  0.623726 -1.073305  0.166613  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "902  1.371062  0.718980 -0.827454 -0.557172  0.235162  0.523978 -0.592003  \n",
       "903  0.518902  0.160598 -1.283986 -0.463894  0.319661  0.785325 -0.294870  \n",
       "904  0.518902  0.160598 -1.283986 -0.463894  0.319661  0.785325 -0.294870  \n",
       "905  2.213172  0.733567 -0.577074 -0.710312 -0.591997  0.836300 -0.720247  \n",
       "906  2.213172  0.733567 -0.577074 -0.710312 -0.591997  0.836300 -0.720247  \n",
       "\n",
       "[907 rows x 258 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.7635,   -0.9828,   -0.4467,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.8511,   -1.7751,    0.6497,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.2911,   -0.9282,    0.2655,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.5044,   -0.5431,    0.9151,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.9591,    0.4688,    0.3871,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   1.1227,   -1.4871,    1.3754,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.5335,   -1.3773,    0.6205,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.6370,   -1.5410,    0.7299,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.5269,   -1.5036,    0.6643,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.6488,   -0.1748,    0.7375,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   1.4133,   -0.7414,    0.1002,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.4118,   -0.7754,    0.8243,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   1.2032,   -1.1528,    0.8183,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.8463,   -1.2633,    0.5078,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.7296,   -1.0356,    0.3907,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.7296,   -1.0356,    0.3907,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   1.1479,   -0.7998,    0.6644,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   1.1479,   -0.7998,    0.6644,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]]], dtype=torch.float64)\n",
      "torch.Size([359, 6, 268])\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\embeddings\\path_embedding.pkl\", \"rb\") as f:\n",
    "    inp = pickle.load(f)\n",
    "\n",
    "bestoutput2[\"filename\"] = bestoutput2[\"file\"].str.split(\"_animation\").str[0]\n",
    "\n",
    "display(bestoutput2)\n",
    "\n",
    "inp['animation_id'] = inp['animation_id'].astype(int)\n",
    "\n",
    "#names = bestoutput2[\"file\"].str.replace(\"_animation_0\", \"\")\n",
    "\n",
    "#input = inp[(inp[\"filename\"].isin(bestoutput2[\"filename\"])) & (inp[\"animation_id\"].isin(bestoutput2[\"animation_id\"]))]\n",
    "input = pd.merge(bestoutput2, inp, on=['filename', 'animation_id'], how='inner')\n",
    "input = input.drop(['model_output', 'label', 'label2', 'file'], axis=1)\n",
    "\n",
    "input = input.sort_values(by=['filename','animation_id'])\n",
    "display(input)\n",
    "filenames = input[\"filename\"].unique()\n",
    "#print(filenames)\n",
    "list = []\n",
    "for name in filenames:\n",
    "    #print(name)\n",
    "    seq = input[input[\"filename\"]==name].loc[:, ~inp.columns.isin([\"filename\",\"animation_id\"])][:4]\n",
    "    #print(seq)\n",
    "    seq = pd.concat([seq, pd.DataFrame(0, index=seq.index, columns=range(256, 268))], axis=1, ignore_index=True)\n",
    "\n",
    "    while len(seq) < 4:\n",
    "        seq = pd.concat([seq, pd.DataFrame([[-100]*268])], ignore_index=True)\n",
    "\n",
    "    sos = pd.DataFrame([[30]*268])\n",
    "    \n",
    "    eos = pd.DataFrame([[50]*268])\n",
    "\n",
    "    seq = pd.concat([sos, seq, eos], ignore_index=True)\n",
    "\n",
    "    list.append(torch.tensor(seq.values))\n",
    "    #print(list)\n",
    "inpTensor2 = torch.stack(list)\n",
    "inpTensor2 = inpTensor2.to(device)\n",
    "print(inpTensor2)\n",
    "print(inpTensor2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.7635, -0.9828, -0.4467,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.8511, -1.7751,  0.6497,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.2911, -0.9282,  0.2655,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.5044, -0.5431,  0.9151,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]]]) torch.Size([1, 6, 268])\n"
     ]
    }
   ],
   "source": [
    "test = inpTensor2[:1,:,:]\n",
    "test = test.to(torch.float32)\n",
    "test = test.to(device)\n",
    "print(test, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.7635,   -0.9828,   -0.4467,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.8511,   -1.7751,    0.6497,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.2911,   -0.9282,    0.2655,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.5044,   -0.5431,    0.9151,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.9591,    0.4688,    0.3871,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   1.1227,   -1.4871,    1.3754,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.5335,   -1.3773,    0.6205,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.6370,   -1.5410,    0.7299,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.5269,   -1.5036,    0.6643,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.6488,   -0.1748,    0.7375,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   1.4133,   -0.7414,    0.1002,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.4118,   -0.7754,    0.8243,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   1.2032,   -1.1528,    0.8183,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.8463,   -1.2633,    0.5078,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [-100.0000, -100.0000, -100.0000,  ..., -100.0000, -100.0000,\n",
      "          -100.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]],\n",
      "\n",
      "        [[  30.0000,   30.0000,   30.0000,  ...,   30.0000,   30.0000,\n",
      "            30.0000],\n",
      "         [   0.7296,   -1.0356,    0.3907,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   0.7296,   -1.0356,    0.3907,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   1.1479,   -0.7998,    0.6644,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [   1.1479,   -0.7998,    0.6644,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  50.0000,   50.0000,   50.0000,  ...,   50.0000,   50.0000,\n",
      "            50.0000]]], dtype=torch.float64) torch.Size([359, 6, 268])\n",
      "tensor([[[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]],\n",
      "\n",
      "        [[30.0000, 30.0000, 30.0000,  ..., 30.0000, 30.0000, 30.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000,  0.8444,  0.7580],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4206, -1.0000, -1.0000],\n",
      "         [50.0000, 50.0000, 50.0000,  ..., 50.0000, 50.0000, 50.0000]]],\n",
      "       dtype=torch.float64) torch.Size([359, 6, 268])\n"
     ]
    }
   ],
   "source": [
    "print(inpTensor2, inpTensor2.shape)\n",
    "\n",
    "print(outTensor2, outTensor2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_tokens,\n",
    "        dim_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dropout_p,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # INFO\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        # LAYERS\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
    "        )\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(dim_model, num_tokens)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None, batch_first=True):\n",
    "        # Src size must be (batch_size, src sequence length)\n",
    "        # Tgt size must be (batch_size, tgt sequence length)\n",
    "\n",
    "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
    "        #src = self.embedding(src) * math.sqrt(self.dim_model)\n",
    "        #tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
    "        src = self.positional_encoder(src)\n",
    "        tgt = self.positional_encoder(tgt)\n",
    "        \n",
    "\n",
    "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
    "        #print(src.shape, tgt.shape)\n",
    "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        out = self.out(transformer_out)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    num_tokens=268, dim_model=268, num_heads=67, num_encoder_layers=4, num_decoder_layers=8, dropout_p=0.01\n",
    ").to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        X, y = batch[0], batch[1]\n",
    "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "\n",
    "        #print(y.shape, y_input, y_input.shape, y_expected, y_expected.shape)\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y.size(1)\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        #print(X.shape, y.shape)\n",
    "        pred = model(X, y)\n",
    "\n",
    "        # Permute pred to have batch size first again\n",
    "        #pred = pred.permute(1, 2, 0)      \n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch[0], batch[1]\n",
    "            X, y = torch.tensor(X, device=device), torch.tensor(y, device=device)\n",
    "\n",
    "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "            y_input = y[:,:-1]\n",
    "            y_expected = y[:,1:]\n",
    "            \n",
    "            # Get mask to mask out the next words\n",
    "            sequence_length = y.size(1)\n",
    "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "            # Standard training except we pass in y_input and src_mask\n",
    "            #print(\"val \", X.shape, y.shape, X.dtype, y.dtype)\n",
    "            pred = model(X, y)\n",
    "\n",
    "            # Permute pred to have batch size first again\n",
    "            #pred = pred.permute(1, 2, 0)      \n",
    "            loss = loss_fn(pred, y)\n",
    "            total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okan2\\AppData\\Local\\Temp\\ipykernel_10012\\4031093003.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
      "C:\\Users\\okan2\\AppData\\Local\\Temp\\ipykernel_10012\\735850417.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = torch.tensor(X, device=device), torch.tensor(y, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 533.0462\n",
      "Validation loss: 498.2730\n",
      "\n",
      "------------------------- Epoch 2 -------------------------\n",
      "Training loss: 475.9472\n",
      "Validation loss: 447.0410\n",
      "\n",
      "------------------------- Epoch 3 -------------------------\n",
      "Training loss: 431.4087\n",
      "Validation loss: 411.1406\n",
      "\n",
      "------------------------- Epoch 4 -------------------------\n",
      "Training loss: 403.5338\n",
      "Validation loss: 394.1416\n",
      "\n",
      "------------------------- Epoch 5 -------------------------\n",
      "Training loss: 392.3020\n",
      "Validation loss: 389.7063\n",
      "\n",
      "------------------------- Epoch 6 -------------------------\n",
      "Training loss: 389.7791\n",
      "Validation loss: 389.1811\n",
      "\n",
      "------------------------- Epoch 7 -------------------------\n",
      "Training loss: 389.3126\n",
      "Validation loss: 389.1575\n",
      "\n",
      "------------------------- Epoch 8 -------------------------\n",
      "Training loss: 389.4195\n",
      "Validation loss: 389.1290\n",
      "\n",
      "------------------------- Epoch 9 -------------------------\n",
      "Training loss: 389.0137\n",
      "Validation loss: 388.8959\n",
      "\n",
      "------------------------- Epoch 10 -------------------------\n",
      "Training loss: 388.4568\n",
      "Validation loss: 389.3601\n",
      "\n",
      "------------------------- Epoch 11 -------------------------\n",
      "Training loss: 388.8905\n",
      "Validation loss: 389.2407\n",
      "\n",
      "------------------------- Epoch 12 -------------------------\n",
      "Training loss: 389.5107\n",
      "Validation loss: 389.1580\n",
      "\n",
      "------------------------- Epoch 13 -------------------------\n",
      "Training loss: 389.2481\n",
      "Validation loss: 389.0206\n",
      "\n",
      "------------------------- Epoch 14 -------------------------\n",
      "Training loss: 389.2121\n",
      "Validation loss: 385.0926\n",
      "\n",
      "------------------------- Epoch 15 -------------------------\n",
      "Training loss: 389.4358\n",
      "Validation loss: 389.4444\n",
      "\n",
      "------------------------- Epoch 16 -------------------------\n",
      "Training loss: 389.5199\n",
      "Validation loss: 389.2931\n",
      "\n",
      "------------------------- Epoch 17 -------------------------\n",
      "Training loss: 389.2281\n",
      "Validation loss: 389.2879\n",
      "\n",
      "------------------------- Epoch 18 -------------------------\n",
      "Training loss: 389.3455\n",
      "Validation loss: 389.2960\n",
      "\n",
      "------------------------- Epoch 19 -------------------------\n",
      "Training loss: 389.3641\n",
      "Validation loss: 389.2164\n",
      "\n",
      "------------------------- Epoch 20 -------------------------\n",
      "Training loss: 389.6446\n",
      "Validation loss: 389.2721\n",
      "\n",
      "------------------------- Epoch 21 -------------------------\n",
      "Training loss: 389.3053\n",
      "Validation loss: 389.2436\n",
      "\n",
      "------------------------- Epoch 22 -------------------------\n",
      "Training loss: 389.4350\n",
      "Validation loss: 389.2371\n",
      "\n",
      "------------------------- Epoch 23 -------------------------\n",
      "Training loss: 389.2607\n",
      "Validation loss: 389.2439\n",
      "\n",
      "------------------------- Epoch 24 -------------------------\n",
      "Training loss: 389.2078\n",
      "Validation loss: 389.2573\n",
      "\n",
      "------------------------- Epoch 25 -------------------------\n",
      "Training loss: 389.4872\n",
      "Validation loss: 389.2515\n",
      "\n",
      "------------------------- Epoch 26 -------------------------\n",
      "Training loss: 389.1777\n",
      "Validation loss: 389.2618\n",
      "\n",
      "------------------------- Epoch 27 -------------------------\n",
      "Training loss: 389.1983\n",
      "Validation loss: 389.2202\n",
      "\n",
      "------------------------- Epoch 28 -------------------------\n",
      "Training loss: 389.2710\n",
      "Validation loss: 389.2421\n",
      "\n",
      "------------------------- Epoch 29 -------------------------\n",
      "Training loss: 388.9539\n",
      "Validation loss: 389.2537\n",
      "\n",
      "------------------------- Epoch 30 -------------------------\n",
      "Training loss: 389.1433\n",
      "Validation loss: 389.2825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(TensorDataset(inpTensor2.float(), outTensor2.float()), batch_size=30, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(TensorDataset(inpTensor2.float(), outTensor2.float()),batch_size=30, shuffle=True,  drop_last=True)\n",
    "\n",
    "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Used for plotting later on\n",
    "    train_loss_list, validation_loss_list = [], []\n",
    "    \n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "        \n",
    "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
    "        train_loss_list += [train_loss]\n",
    "        \n",
    "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
    "        validation_loss_list += [validation_loss]\n",
    "        \n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "        print()\n",
    "        \n",
    "    return train_loss_list, validation_loss_list\n",
    "    \n",
    "train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_list, label='Training Loss')\n",
    "plt.plot(validation_loss_list, label='Validation Loss')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_sequence, max_length=6, SOS_token=[[30] * 268], EOS_token=[[50] * 268]):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    y_input = torch.tensor([SOS_token], dtype=torch.long, device=device)\n",
    "    \n",
    "    num_tokens = len(input_sequence[0])\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Get source mask\n",
    "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
    "        \n",
    "        pred = model(input_sequence, y_input, tgt_mask)\n",
    "        \n",
    "        next_item = pred.topk(1)[1] # num with highest probability\n",
    "        #next_item = torch.tensor([[next_item]], device=device)\n",
    "\n",
    "        next_item = pred[:,:1,:]\n",
    "        #print(next_item, next_item.shape)\n",
    "\n",
    "        #print(input_sequence.shape, y_input.shape, next_item.shape, pred.shape)\n",
    "        # Concatenate previous input with predicted best word\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "\n",
    "        # Stop if model predicts end of sentence\n",
    "        if next_item == EOS_token:\n",
    "            break\n",
    "\n",
    "    return y_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(model, test)\n",
    "\n",
    "model_parameters = result[:,1:2,-12:].squeeze().tolist()\n",
    "model_parameters = [value - math.floor(value) for value in model_parameters]\n",
    "model_parameters = [round(value) if index < 6 else value for index, value in enumerate(model_parameters)]\n",
    "print(model_parameters)\n",
    "\n",
    "model_parameters = pd.DataFrame({\"animation_id\" : 2, \"model_output\" : [model_parameters]})\n",
    "\n",
    "print(model_parameters, model_parameters.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(model, test)\n",
    "\n",
    "model_parameters = result[:,1:,-12:].squeeze(0).detach().numpy()\n",
    "print(model_parameters.shape)\n",
    "\n",
    "model_parameters = pd.DataFrame(model_parameters)\n",
    "model_parameters[\"model_output\"] = model_parameters.apply(lambda row: row.tolist(), axis=1)\n",
    "\n",
    "def process_model_output(lst):\n",
    "    # Floor all values in the list\n",
    "    lst = [value - math.floor(value) for value in lst]\n",
    "    \n",
    "    # Round the first 6 values in the list\n",
    "    lst[:6] = [round(value) for value in lst[:6]]\n",
    "    \n",
    "    return lst\n",
    "\n",
    "# Apply the custom function to the \"model_output\" column\n",
    "model_parameters = model_parameters[['model_output']]\n",
    "model_parameters['model_output'] = model_parameters['model_output'].apply(process_model_output)\n",
    "\n",
    "model_parameters[\"animation_id\"] = range(1, len(model_parameters)+1)\n",
    "print(model_parameters, model_parameters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.postprocessing.postprocessing import *\n",
    "\n",
    "postprocess_logo(model_parameters, \"data/1_inserted_animation_id/logo_0.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animationSVG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
