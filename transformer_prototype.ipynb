{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset,random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Okan\\\\Desktop\\\\Team Project'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os\n",
    "#os.chdir(\"./../.\")\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x15f0ad7a490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        batch_size = Q.size()[0]\n",
    "        seq_length = Q.size()[1]\n",
    "        #mask = mask.view(batch_size, 1, 1, seq_length).expand(-1, self.num_heads, -1, -1)\n",
    "        mask = mask.unsqueeze(1).unsqueeze(1).expand(-1, self.num_heads, -1, -1)\n",
    "        mask = mask.permute(0, 1, 3, 2)\n",
    "        #print(\"mask shape:\",mask.shape)\n",
    "        #print(attn_scores.shape)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == True, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        #print(\"Q:\",Q.shape)\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "\n",
    "        #d_ff: dimension of hidden layer\n",
    "\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding2(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding2, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFromscratch(nn.Module):\n",
    "    def __init__(self, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(TransformerFromscratch, self).__init__()\n",
    "        #self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        #self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding2(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 10).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 10).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        print(\"seq_length\",seq_length)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        print(\"nopeak:\",nopeak_mask.shape)\n",
    "        print(\"tgt_mask:\",tgt_mask.shape)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "    \n",
    "    def create_pad_mask(self, input : torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "\n",
    "        t = []\n",
    "        for seq in input:\n",
    "            list =[]\n",
    "            for token in seq:\n",
    "                b = False\n",
    "                for value in token:\n",
    "                    if value == pad_token:\n",
    "                        b = True\n",
    "                list.append(b)\n",
    "            t.append(list)\n",
    "        return torch.tensor(t)\n",
    "\n",
    "        #return (input == pad_token)\n",
    "    \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a square matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        #src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_mask = self.create_pad_mask(src,pad_token=10).to(device)\n",
    "        tgt_mask = self.create_pad_mask(tgt,pad_token=10).to(device)\n",
    "        src_embedded = self.dropout(self.positional_encoding(src))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(tgt))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = TransformerFromscratch(tgt_vocab_size=268, d_model=268, num_heads=4, num_layers=8, d_ff=2048, dropout=0.1,max_seq_length=10)\n",
    "model2.to(device)\n",
    "opt = torch.optim.SGD(model2.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    \n",
    "    for batch in dataloader:\n",
    "        X, y = batch[0], batch[1]\n",
    "        #X, y = torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        #sequence_length = y.size(1)\n",
    "        #tgt_mask = model.get_tgt_mask(sequence_length)\n",
    "        \n",
    "        #print(y.view(y.size(0), -1).shape)\n",
    "        #pad_mask = model.create_pad_mask(y, pad_token=-100)\n",
    "        #print(pad_mask)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        \n",
    "        #print(torch.isnan(X).any())\n",
    "        #print(torch.isnan(y).any())\n",
    "\n",
    "        #pred = model(X, y, tgt_mask, pad_mask)\n",
    "\n",
    "        pred = model2(X,y)\n",
    "\n",
    "        #print(\"pred shape:\",pred.shape)\n",
    "        #print(\"y shape:\",y.shape)\n",
    "\n",
    "        y_flattened = y.contiguous().view(-1)\n",
    "\n",
    "        #print(y_flattened)\n",
    "\n",
    "        # Permute pred to have batch size first again\n",
    "        #pred = pred.permute(1, 2, 0)      \n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        #print(\"prediction:\",pred)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # tryign to print the gradient\n",
    "        #for p in model.parameters():\n",
    "        #    print(p.grad.norm())\n",
    "\n",
    "        #for name, param in model2.named_parameters():\n",
    "        #    if 'weight' in name:\n",
    "         #       print(name)\n",
    "         #       print(param.data.cpu().numpy().shape)\n",
    "         #       print('gradient is \\t', param.grad, '\\trequires grad: ', param.requires_grad)\n",
    "\n",
    "        # gradient clipping to avoid the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_value_(model2.parameters(), 10.)\n",
    "\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train = TensorDataset(inpTensor2.float(), outTensor2.float())\n",
    "batch_size = 200 # Set your desired batch size\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)  # For input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n",
      "Training loss: 620.0747\n",
      "\n",
      "------------------------- Epoch 2 -------------------------\n",
      "Training loss: 586.9604\n",
      "\n",
      "------------------------- Epoch 3 -------------------------\n",
      "Training loss: 560.4023\n",
      "\n",
      "------------------------- Epoch 4 -------------------------\n",
      "Training loss: 535.7889\n",
      "\n",
      "------------------------- Epoch 5 -------------------------\n",
      "Training loss: 507.6911\n",
      "\n",
      "------------------------- Epoch 6 -------------------------\n",
      "Training loss: 480.7698\n",
      "\n",
      "------------------------- Epoch 7 -------------------------\n",
      "Training loss: 454.3157\n",
      "\n",
      "------------------------- Epoch 8 -------------------------\n",
      "Training loss: 426.2244\n",
      "\n",
      "------------------------- Epoch 9 -------------------------\n",
      "Training loss: 397.7719\n",
      "\n",
      "------------------------- Epoch 10 -------------------------\n",
      "Training loss: 370.1154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit(model, opt, loss_fn, train_dataloader, epochs):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Used for plotting later on\n",
    "    train_loss_list, validation_loss_list = [], []\n",
    "    \n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "        \n",
    "        train_loss = train_loop(model2, opt, loss_fn, train_dataloader)\n",
    "        train_loss_list += [train_loss]\n",
    "        \n",
    "        #validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
    "        #validation_loss_list += [validation_loss]\n",
    "        \n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        #print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "        print()\n",
    "        \n",
    "    return train_loss_list, validation_loss_list\n",
    "    \n",
    "train_loss_list, validation_loss_list = fit(model2, opt, loss_fn, train_dataloader, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the output 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "torch.__version__\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okan2\\AppData\\Local\\Temp\\ipykernel_3092\\445249230.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_output2['label2'] = filtered_output2['label'].replace(mapping_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>animation_id</th>\n",
       "      <th>model_output</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, -1.0, -1.0, -1.0, 0.4205715...</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>21</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.4...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file  animation_id  \\\n",
       "436   logo_0_animation_0             0   \n",
       "439   logo_0_animation_0             1   \n",
       "438   logo_0_animation_0             3   \n",
       "437   logo_0_animation_0             4   \n",
       "435   logo_0_animation_0             5   \n",
       "..                   ...           ...   \n",
       "892  logo_99_animation_0            21   \n",
       "811  logo_99_animation_0            22   \n",
       "891  logo_99_animation_0            22   \n",
       "810  logo_99_animation_0            23   \n",
       "890  logo_99_animation_0            23   \n",
       "\n",
       "                                          model_output      label  label2  \n",
       "436  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...       Good     5.0  \n",
       "439  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0  \n",
       "438  [0, 0, 0, 0, 0, 1, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0  \n",
       "437  [0, 0, 1, 0, 0, 0, -1.0, -1.0, -1.0, 0.4205715...       Good     5.0  \n",
       "435  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0  \n",
       "..                                                 ...        ...     ...  \n",
       "892  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.4...  Very Good     6.0  \n",
       "811  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...  Very Good     6.0  \n",
       "891  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...  Very Good     6.0  \n",
       "810  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....  Very Good     6.0  \n",
       "890  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....  Very Good     6.0  \n",
       "\n",
       "[907 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50., dtype=torch.float64)\n",
      "torch.Size([359, 6, 268])\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/surrogate_model/animation_label.pkl\", \"rb\") as f:\n",
    "    surrogate2 = pickle.load(f)\n",
    "\n",
    "#Filter with only good or very good ratings\n",
    "#filtered_output = surrogate[surrogate)][['label'].isin(['Good','Very Good'][\"file\",\"animation_id\",\"model_output\",\"label\"]]\n",
    "filtered_output2 = surrogate2[[\"file\",\"animation_id\",\"model_output\",\"label\"]]\n",
    "\n",
    "# dictionary for mapping\n",
    "\n",
    "mapping_dict = {\"Very Good\": 6, \"Good\": 5, \"Bad\": 4,\"Okay\":3, \"Very Bad\": 2, \"no_rating\": 1}\n",
    "\n",
    "# Create another column changing the label into ints\n",
    "\n",
    "filtered_output2['label2'] = filtered_output2['label'].replace(mapping_dict)\n",
    "\n",
    "\n",
    "# get the names of unique logos by splitting with animation number\n",
    "logos = filtered_output2[\"file\"].str.split(\"_animation\").str[0].unique()\n",
    "\n",
    "#print(logos)\n",
    "\n",
    "# create a data frame for the collected best animations\n",
    "bestoutput2 = pd.DataFrame()\n",
    "\n",
    "# go through each logo to find the best animation\n",
    "for logo in logos:\n",
    "\n",
    "    # make a data frame that contains all the animations of one logo\n",
    "    temp = filtered_output2[filtered_output2[\"file\"].str.contains(logo)]\n",
    "\n",
    "    #display(temp)\n",
    "\n",
    "    # create a sum \n",
    "    mean_by_label = temp.groupby('file')['label2'].mean().reset_index()\n",
    "\n",
    "    #print(mean_by_label)\n",
    "\n",
    "    bestlogo = mean_by_label.loc[mean_by_label['label2'].idxmax()]\n",
    "\n",
    "    #print(bestlogo)\n",
    "\n",
    "    # get all the animated paths with the best animation of the logo\n",
    "    best_animations2 = temp[temp[\"file\"]==bestlogo[\"file\"]]\n",
    "\n",
    "    # add to the file\n",
    "    bestoutput2 = pd.concat([bestoutput2,best_animations2],axis=0, ignore_index=True)\n",
    "bestoutput2 = bestoutput2.sort_values(by=['file','animation_id'])\n",
    "display(bestoutput2)\n",
    "\n",
    "filenames = bestoutput2[\"file\"].unique()\n",
    "list = []\n",
    "for name in filenames:\n",
    "    seq = bestoutput2[bestoutput2[\"file\"]==name]\n",
    "    seq = seq[\"model_output\"]\n",
    "    seq = pd.DataFrame(bestoutput2[\"model_output\"].to_list(), columns=[\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"a7\",\"a8\",\"a9\",\"a10\",\"a11\",\"a12\"])\n",
    "    \n",
    "    seq = pd.concat([pd.DataFrame(10, index=seq.index, columns=range(0, 256)), seq], axis=1, ignore_index=True)\n",
    "    \n",
    "    if len(seq) > 4:\n",
    "        seq = seq[:4]\n",
    "\n",
    "    sos = pd.DataFrame([[30]*268])\n",
    "    \n",
    "    eos = pd.DataFrame([[50]*268])\n",
    "\n",
    "    seq = pd.concat([sos, seq, eos], ignore_index=True)\n",
    "    \n",
    "    while len(seq) < 6:\n",
    "           seq = pd.concat([seq, pd.DataFrame([[-100]*268])], ignore_index=True)\n",
    "           \n",
    "    #seq = seq.apply(lambda x: np.array(x).astype(np.float32))\n",
    "    #tokens = []\n",
    "    #for l in seq:\n",
    "    #    tokens.append(torch.tensor(l))\n",
    "\n",
    "    list.append(torch.tensor(seq.values))\n",
    "outTensor2 = torch.stack(list)\n",
    "\n",
    "outTensor2 = outTensor2.to(device)\n",
    "print(outTensor2.max())\n",
    "print(outTensor2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the input tensor with the diltered output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>animation_id</th>\n",
       "      <th>model_output</th>\n",
       "      <th>label</th>\n",
       "      <th>label2</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, -1.0, -1.0, -1.0, 0.4205715...</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>logo_0_animation_0</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>logo_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>21</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.4...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>22</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>logo_99_animation_0</td>\n",
       "      <td>23</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>logo_99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file  animation_id  \\\n",
       "436   logo_0_animation_0             0   \n",
       "439   logo_0_animation_0             1   \n",
       "438   logo_0_animation_0             3   \n",
       "437   logo_0_animation_0             4   \n",
       "435   logo_0_animation_0             5   \n",
       "..                   ...           ...   \n",
       "892  logo_99_animation_0            21   \n",
       "811  logo_99_animation_0            22   \n",
       "891  logo_99_animation_0            22   \n",
       "810  logo_99_animation_0            23   \n",
       "890  logo_99_animation_0            23   \n",
       "\n",
       "                                          model_output      label  label2  \\\n",
       "436  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...       Good     5.0   \n",
       "439  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0   \n",
       "438  [0, 0, 0, 0, 0, 1, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0   \n",
       "437  [0, 0, 1, 0, 0, 0, -1.0, -1.0, -1.0, 0.4205715...       Good     5.0   \n",
       "435  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....       Good     5.0   \n",
       "..                                                 ...        ...     ...   \n",
       "892  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.4...  Very Good     6.0   \n",
       "811  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...  Very Good     6.0   \n",
       "891  [0, 0, 0, 1, 0, 0, -1.0, -1.0, -1.0, -1.0, 0.8...  Very Good     6.0   \n",
       "810  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....  Very Good     6.0   \n",
       "890  [0, 0, 0, 0, 1, 0, -1.0, -1.0, -1.0, -1.0, -1....  Very Good     6.0   \n",
       "\n",
       "    filename  \n",
       "436   logo_0  \n",
       "439   logo_0  \n",
       "438   logo_0  \n",
       "437   logo_0  \n",
       "435   logo_0  \n",
       "..       ...  \n",
       "892  logo_99  \n",
       "811  logo_99  \n",
       "891  logo_99  \n",
       "810  logo_99  \n",
       "890  logo_99  \n",
       "\n",
       "[907 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animation_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.763518</td>\n",
       "      <td>-0.982797</td>\n",
       "      <td>-0.446681</td>\n",
       "      <td>1.089468</td>\n",
       "      <td>-0.070563</td>\n",
       "      <td>0.710206</td>\n",
       "      <td>-0.491675</td>\n",
       "      <td>-1.631172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339061</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.195161</td>\n",
       "      <td>-0.046488</td>\n",
       "      <td>-0.492103</td>\n",
       "      <td>-0.605836</td>\n",
       "      <td>-1.282879</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>0.297194</td>\n",
       "      <td>-0.172312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.851117</td>\n",
       "      <td>-1.775123</td>\n",
       "      <td>0.649689</td>\n",
       "      <td>-0.688600</td>\n",
       "      <td>0.216071</td>\n",
       "      <td>0.135211</td>\n",
       "      <td>-1.748761</td>\n",
       "      <td>-1.347670</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.616431</td>\n",
       "      <td>-1.572003</td>\n",
       "      <td>0.242460</td>\n",
       "      <td>0.430259</td>\n",
       "      <td>0.079752</td>\n",
       "      <td>-1.039526</td>\n",
       "      <td>-0.696104</td>\n",
       "      <td>0.090277</td>\n",
       "      <td>-0.228757</td>\n",
       "      <td>0.144372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.291136</td>\n",
       "      <td>-0.928242</td>\n",
       "      <td>0.265542</td>\n",
       "      <td>-0.261439</td>\n",
       "      <td>-0.386160</td>\n",
       "      <td>1.256256</td>\n",
       "      <td>-0.414706</td>\n",
       "      <td>-1.206105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.446020</td>\n",
       "      <td>-1.369758</td>\n",
       "      <td>0.356421</td>\n",
       "      <td>1.456656</td>\n",
       "      <td>0.468766</td>\n",
       "      <td>-1.077724</td>\n",
       "      <td>-0.548627</td>\n",
       "      <td>-0.300660</td>\n",
       "      <td>0.632805</td>\n",
       "      <td>-0.136473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.504446</td>\n",
       "      <td>-0.543099</td>\n",
       "      <td>0.915062</td>\n",
       "      <td>1.293575</td>\n",
       "      <td>-0.849605</td>\n",
       "      <td>1.120387</td>\n",
       "      <td>-0.637641</td>\n",
       "      <td>-1.337280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162753</td>\n",
       "      <td>0.206993</td>\n",
       "      <td>-0.201259</td>\n",
       "      <td>-1.087391</td>\n",
       "      <td>-0.597388</td>\n",
       "      <td>-0.992079</td>\n",
       "      <td>-0.851486</td>\n",
       "      <td>-0.225463</td>\n",
       "      <td>-0.549269</td>\n",
       "      <td>0.088637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>-0.641569</td>\n",
       "      <td>-0.657125</td>\n",
       "      <td>-0.105109</td>\n",
       "      <td>-0.031630</td>\n",
       "      <td>-0.572032</td>\n",
       "      <td>0.912017</td>\n",
       "      <td>-0.569627</td>\n",
       "      <td>-1.573482</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.079276</td>\n",
       "      <td>0.285482</td>\n",
       "      <td>1.532865</td>\n",
       "      <td>-0.375210</td>\n",
       "      <td>-0.249130</td>\n",
       "      <td>-0.551393</td>\n",
       "      <td>-1.024246</td>\n",
       "      <td>0.623726</td>\n",
       "      <td>-1.073305</td>\n",
       "      <td>0.166613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>21</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>0.729620</td>\n",
       "      <td>-1.035586</td>\n",
       "      <td>0.390709</td>\n",
       "      <td>1.910684</td>\n",
       "      <td>-0.489203</td>\n",
       "      <td>2.197111</td>\n",
       "      <td>0.424709</td>\n",
       "      <td>-0.389426</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130544</td>\n",
       "      <td>-1.892641</td>\n",
       "      <td>-0.690288</td>\n",
       "      <td>1.371062</td>\n",
       "      <td>0.718980</td>\n",
       "      <td>-0.827454</td>\n",
       "      <td>-0.557172</td>\n",
       "      <td>0.235162</td>\n",
       "      <td>0.523978</td>\n",
       "      <td>-0.592003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>22</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.147938</td>\n",
       "      <td>-0.799806</td>\n",
       "      <td>0.664411</td>\n",
       "      <td>1.610482</td>\n",
       "      <td>-0.612273</td>\n",
       "      <td>1.194499</td>\n",
       "      <td>0.076532</td>\n",
       "      <td>-0.662109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415811</td>\n",
       "      <td>-1.569571</td>\n",
       "      <td>-0.424470</td>\n",
       "      <td>0.518902</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>-1.283986</td>\n",
       "      <td>-0.463894</td>\n",
       "      <td>0.319661</td>\n",
       "      <td>0.785325</td>\n",
       "      <td>-0.294870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>22</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.147938</td>\n",
       "      <td>-0.799806</td>\n",
       "      <td>0.664411</td>\n",
       "      <td>1.610482</td>\n",
       "      <td>-0.612273</td>\n",
       "      <td>1.194499</td>\n",
       "      <td>0.076532</td>\n",
       "      <td>-0.662109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415811</td>\n",
       "      <td>-1.569571</td>\n",
       "      <td>-0.424470</td>\n",
       "      <td>0.518902</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>-1.283986</td>\n",
       "      <td>-0.463894</td>\n",
       "      <td>0.319661</td>\n",
       "      <td>0.785325</td>\n",
       "      <td>-0.294870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>23</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.645128</td>\n",
       "      <td>-1.911424</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>0.850210</td>\n",
       "      <td>0.554424</td>\n",
       "      <td>1.578238</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.704658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883759</td>\n",
       "      <td>-2.000007</td>\n",
       "      <td>-0.517095</td>\n",
       "      <td>2.213172</td>\n",
       "      <td>0.733567</td>\n",
       "      <td>-0.577074</td>\n",
       "      <td>-0.710312</td>\n",
       "      <td>-0.591997</td>\n",
       "      <td>0.836300</td>\n",
       "      <td>-0.720247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>23</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.645128</td>\n",
       "      <td>-1.911424</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>0.850210</td>\n",
       "      <td>0.554424</td>\n",
       "      <td>1.578238</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.704658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883759</td>\n",
       "      <td>-2.000007</td>\n",
       "      <td>-0.517095</td>\n",
       "      <td>2.213172</td>\n",
       "      <td>0.733567</td>\n",
       "      <td>-0.577074</td>\n",
       "      <td>-0.710312</td>\n",
       "      <td>-0.591997</td>\n",
       "      <td>0.836300</td>\n",
       "      <td>-0.720247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     animation_id filename         0         1         2         3         4  \\\n",
       "0               0   logo_0  0.763518 -0.982797 -0.446681  1.089468 -0.070563   \n",
       "1               1   logo_0  0.851117 -1.775123  0.649689 -0.688600  0.216071   \n",
       "2               3   logo_0  0.291136 -0.928242  0.265542 -0.261439 -0.386160   \n",
       "3               4   logo_0  0.504446 -0.543099  0.915062  1.293575 -0.849605   \n",
       "4               5   logo_0 -0.641569 -0.657125 -0.105109 -0.031630 -0.572032   \n",
       "..            ...      ...       ...       ...       ...       ...       ...   \n",
       "902            21  logo_99  0.729620 -1.035586  0.390709  1.910684 -0.489203   \n",
       "903            22  logo_99  1.147938 -0.799806  0.664411  1.610482 -0.612273   \n",
       "904            22  logo_99  1.147938 -0.799806  0.664411  1.610482 -0.612273   \n",
       "905            23  logo_99  1.645128 -1.911424  0.806118  0.850210  0.554424   \n",
       "906            23  logo_99  1.645128 -1.911424  0.806118  0.850210  0.554424   \n",
       "\n",
       "            5         6         7  ...       246       247       248  \\\n",
       "0    0.710206 -0.491675 -1.631172  ...  0.339061  0.022934  0.195161   \n",
       "1    0.135211 -1.748761 -1.347670  ... -1.616431 -1.572003  0.242460   \n",
       "2    1.256256 -0.414706 -1.206105  ... -0.446020 -1.369758  0.356421   \n",
       "3    1.120387 -0.637641 -1.337280  ...  0.162753  0.206993 -0.201259   \n",
       "4    0.912017 -0.569627 -1.573482  ... -1.079276  0.285482  1.532865   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "902  2.197111  0.424709 -0.389426  ...  1.130544 -1.892641 -0.690288   \n",
       "903  1.194499  0.076532 -0.662109  ...  0.415811 -1.569571 -0.424470   \n",
       "904  1.194499  0.076532 -0.662109  ...  0.415811 -1.569571 -0.424470   \n",
       "905  1.578238 -0.722733 -0.704658  ...  0.883759 -2.000007 -0.517095   \n",
       "906  1.578238 -0.722733 -0.704658  ...  0.883759 -2.000007 -0.517095   \n",
       "\n",
       "          249       250       251       252       253       254       255  \n",
       "0   -0.046488 -0.492103 -0.605836 -1.282879  0.613195  0.297194 -0.172312  \n",
       "1    0.430259  0.079752 -1.039526 -0.696104  0.090277 -0.228757  0.144372  \n",
       "2    1.456656  0.468766 -1.077724 -0.548627 -0.300660  0.632805 -0.136473  \n",
       "3   -1.087391 -0.597388 -0.992079 -0.851486 -0.225463 -0.549269  0.088637  \n",
       "4   -0.375210 -0.249130 -0.551393 -1.024246  0.623726 -1.073305  0.166613  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "902  1.371062  0.718980 -0.827454 -0.557172  0.235162  0.523978 -0.592003  \n",
       "903  0.518902  0.160598 -1.283986 -0.463894  0.319661  0.785325 -0.294870  \n",
       "904  0.518902  0.160598 -1.283986 -0.463894  0.319661  0.785325 -0.294870  \n",
       "905  2.213172  0.733567 -0.577074 -0.710312 -0.591997  0.836300 -0.720247  \n",
       "906  2.213172  0.733567 -0.577074 -0.710312 -0.591997  0.836300 -0.720247  \n",
       "\n",
       "[907 rows x 258 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([359, 6, 268])\n"
     ]
    }
   ],
   "source": [
    "with open(\"data\\embeddings\\path_embedding.pkl\", \"rb\") as f:\n",
    "    inp = pickle.load(f)\n",
    "\n",
    "bestoutput2[\"filename\"] = bestoutput2[\"file\"].str.split(\"_animation\").str[0]\n",
    "\n",
    "display(bestoutput2)\n",
    "\n",
    "inp['animation_id'] = inp['animation_id'].astype(int)\n",
    "\n",
    "#names = bestoutput2[\"file\"].str.replace(\"_animation_0\", \"\")\n",
    "\n",
    "#input = inp[(inp[\"filename\"].isin(bestoutput2[\"filename\"])) & (inp[\"animation_id\"].isin(bestoutput2[\"animation_id\"]))]\n",
    "input = pd.merge(bestoutput2, inp, on=['filename', 'animation_id'],how='inner')\n",
    "input = input.drop(['model_output', 'label','label2','file'], axis=1)\n",
    "\n",
    "input = input.sort_values(by=['filename','animation_id'])\n",
    "display(input)\n",
    "filenames = input[\"filename\"].unique()\n",
    "#print(filenames)\n",
    "list = []\n",
    "for name in filenames:\n",
    "    #print(name)\n",
    "    seq = input[input[\"filename\"]==name].loc[:, ~inp.columns.isin([\"filename\",\"animation_id\"])][:4]\n",
    "    #print(seq)\n",
    "    seq = pd.concat([seq, pd.DataFrame(10, index=seq.index, columns=range(256, 268))], axis=1, ignore_index=True)\n",
    "\n",
    "    while len(seq) < 4:\n",
    "        seq = pd.concat([seq, pd.DataFrame([[10]*268])], ignore_index=True)\n",
    "\n",
    "    sos = pd.DataFrame([[30]*268])\n",
    "\n",
    "    \n",
    "    eos = pd.DataFrame([[50]*268])\n",
    "\n",
    "    seq = pd.concat([sos, seq, eos], ignore_index=True)\n",
    "\n",
    "    list.append(torch.tensor(seq.values))\n",
    "    #print(list)\n",
    "inpTensor2 = torch.stack(list)\n",
    "inpTensor2 = inpTensor2.to(device)\n",
    "print(inpTensor2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 268])\n"
     ]
    }
   ],
   "source": [
    "test = inpTensor2[:1,:,:]\n",
    "test = test.to(torch.float32)\n",
    "test = test.to\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 268]) torch.Size([1, 1, 268])\n",
      "torch.Size([1, 6, 268])\n",
      "torch.Size([1, 1, 268])\n",
      "torch.Size([268])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 268 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Okan\\Desktop\\Team Project\\Animate_SVG_v2\\transformer_prototype.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Okan/Desktop/Team%20Project/Animate_SVG_v2/transformer_prototype.ipynb#Y105sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Okan/Desktop/Team%20Project/Animate_SVG_v2/transformer_prototype.ipynb#Y105sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m y_input\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Okan/Desktop/Team%20Project/Animate_SVG_v2/transformer_prototype.ipynb#Y105sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m svg_animations \u001b[39m=\u001b[39m predict(model2, test)\n",
      "\u001b[1;32mc:\\Users\\Okan\\Desktop\\Team Project\\Animate_SVG_v2\\transformer_prototype.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Okan/Desktop/Team%20Project/Animate_SVG_v2/transformer_prototype.ipynb#Y105sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# Stop if model predicts end of sentence\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Okan/Desktop/Team%20Project/Animate_SVG_v2/transformer_prototype.ipynb#Y105sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mprint\u001b[39m(next_item\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Okan/Desktop/Team%20Project/Animate_SVG_v2/transformer_prototype.ipynb#Y105sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mif\u001b[39;00m next_item\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mitem() \u001b[39m==\u001b[39m [EOS_token\u001b[39m*\u001b[39m\u001b[39m268\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Okan/Desktop/Team%20Project/Animate_SVG_v2/transformer_prototype.ipynb#Y105sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Okan/Desktop/Team%20Project/Animate_SVG_v2/transformer_prototype.ipynb#Y105sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m y_input\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 268 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "def predict(model, input_sequence, max_length=6, SOS_token=[30 * 268], EOS_token=50):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    y_input = torch.tensor([[[SOS_token]*268]], dtype=torch.float32)\n",
    "\n",
    "    num_tokens = len(input_sequence[0])\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Get source mask\n",
    "        #tgt_mask = model.get_tgt_mask(y_input.size(1))\n",
    "        \n",
    "        print(input_sequence.shape, y_input.shape)\n",
    "        pred = model(input_sequence, y_input)\n",
    "        print(pred.shape)\n",
    "        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
    "        next_item = torch.tensor([[next_item]])\n",
    "        \n",
    "        next_item = pred[:,:1,:]\n",
    "        print(next_item.shape)\n",
    "\n",
    "        #print(y_input, next_item)\n",
    "        # Concatenate previous input with predicted best word\n",
    "        #print(y_input.shape, next_item.shape)\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "\n",
    "        # Stop if model predicts end of sentence\n",
    "        print(next_item.view(-1).shape)\n",
    "        if next_item.view(-1).item() == [EOS_token*268]:\n",
    "            break\n",
    "\n",
    "    return y_input.view(-1).tolist()\n",
    "\n",
    "svg_animations = predict(model2, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animation_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.763518</td>\n",
       "      <td>-0.982797</td>\n",
       "      <td>-0.446681</td>\n",
       "      <td>1.089468</td>\n",
       "      <td>-0.070563</td>\n",
       "      <td>0.710206</td>\n",
       "      <td>-0.491675</td>\n",
       "      <td>-1.631172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339061</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.195161</td>\n",
       "      <td>-0.046488</td>\n",
       "      <td>-0.492103</td>\n",
       "      <td>-0.605836</td>\n",
       "      <td>-1.282879</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>0.297194</td>\n",
       "      <td>-0.172312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.851117</td>\n",
       "      <td>-1.775123</td>\n",
       "      <td>0.649689</td>\n",
       "      <td>-0.688600</td>\n",
       "      <td>0.216071</td>\n",
       "      <td>0.135211</td>\n",
       "      <td>-1.748761</td>\n",
       "      <td>-1.347670</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.616431</td>\n",
       "      <td>-1.572003</td>\n",
       "      <td>0.242460</td>\n",
       "      <td>0.430259</td>\n",
       "      <td>0.079752</td>\n",
       "      <td>-1.039526</td>\n",
       "      <td>-0.696104</td>\n",
       "      <td>0.090277</td>\n",
       "      <td>-0.228757</td>\n",
       "      <td>0.144372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.291136</td>\n",
       "      <td>-0.928242</td>\n",
       "      <td>0.265542</td>\n",
       "      <td>-0.261439</td>\n",
       "      <td>-0.386160</td>\n",
       "      <td>1.256256</td>\n",
       "      <td>-0.414706</td>\n",
       "      <td>-1.206105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.446020</td>\n",
       "      <td>-1.369758</td>\n",
       "      <td>0.356421</td>\n",
       "      <td>1.456656</td>\n",
       "      <td>0.468766</td>\n",
       "      <td>-1.077724</td>\n",
       "      <td>-0.548627</td>\n",
       "      <td>-0.300660</td>\n",
       "      <td>0.632805</td>\n",
       "      <td>-0.136473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>0.504446</td>\n",
       "      <td>-0.543099</td>\n",
       "      <td>0.915062</td>\n",
       "      <td>1.293575</td>\n",
       "      <td>-0.849605</td>\n",
       "      <td>1.120387</td>\n",
       "      <td>-0.637641</td>\n",
       "      <td>-1.337280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162753</td>\n",
       "      <td>0.206993</td>\n",
       "      <td>-0.201259</td>\n",
       "      <td>-1.087391</td>\n",
       "      <td>-0.597388</td>\n",
       "      <td>-0.992079</td>\n",
       "      <td>-0.851486</td>\n",
       "      <td>-0.225463</td>\n",
       "      <td>-0.549269</td>\n",
       "      <td>0.088637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>logo_0</td>\n",
       "      <td>-0.641569</td>\n",
       "      <td>-0.657125</td>\n",
       "      <td>-0.105109</td>\n",
       "      <td>-0.031630</td>\n",
       "      <td>-0.572032</td>\n",
       "      <td>0.912017</td>\n",
       "      <td>-0.569627</td>\n",
       "      <td>-1.573482</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.079276</td>\n",
       "      <td>0.285482</td>\n",
       "      <td>1.532865</td>\n",
       "      <td>-0.375210</td>\n",
       "      <td>-0.249130</td>\n",
       "      <td>-0.551393</td>\n",
       "      <td>-1.024246</td>\n",
       "      <td>0.623726</td>\n",
       "      <td>-1.073305</td>\n",
       "      <td>0.166613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>21</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>0.729620</td>\n",
       "      <td>-1.035586</td>\n",
       "      <td>0.390709</td>\n",
       "      <td>1.910684</td>\n",
       "      <td>-0.489203</td>\n",
       "      <td>2.197111</td>\n",
       "      <td>0.424709</td>\n",
       "      <td>-0.389426</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130544</td>\n",
       "      <td>-1.892641</td>\n",
       "      <td>-0.690288</td>\n",
       "      <td>1.371062</td>\n",
       "      <td>0.718980</td>\n",
       "      <td>-0.827454</td>\n",
       "      <td>-0.557172</td>\n",
       "      <td>0.235162</td>\n",
       "      <td>0.523978</td>\n",
       "      <td>-0.592003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>22</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.147938</td>\n",
       "      <td>-0.799806</td>\n",
       "      <td>0.664411</td>\n",
       "      <td>1.610482</td>\n",
       "      <td>-0.612273</td>\n",
       "      <td>1.194499</td>\n",
       "      <td>0.076532</td>\n",
       "      <td>-0.662109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415811</td>\n",
       "      <td>-1.569571</td>\n",
       "      <td>-0.424470</td>\n",
       "      <td>0.518902</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>-1.283986</td>\n",
       "      <td>-0.463894</td>\n",
       "      <td>0.319661</td>\n",
       "      <td>0.785325</td>\n",
       "      <td>-0.294870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>22</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.147938</td>\n",
       "      <td>-0.799806</td>\n",
       "      <td>0.664411</td>\n",
       "      <td>1.610482</td>\n",
       "      <td>-0.612273</td>\n",
       "      <td>1.194499</td>\n",
       "      <td>0.076532</td>\n",
       "      <td>-0.662109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415811</td>\n",
       "      <td>-1.569571</td>\n",
       "      <td>-0.424470</td>\n",
       "      <td>0.518902</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>-1.283986</td>\n",
       "      <td>-0.463894</td>\n",
       "      <td>0.319661</td>\n",
       "      <td>0.785325</td>\n",
       "      <td>-0.294870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>23</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.645128</td>\n",
       "      <td>-1.911424</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>0.850210</td>\n",
       "      <td>0.554424</td>\n",
       "      <td>1.578238</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.704658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883759</td>\n",
       "      <td>-2.000007</td>\n",
       "      <td>-0.517095</td>\n",
       "      <td>2.213172</td>\n",
       "      <td>0.733567</td>\n",
       "      <td>-0.577074</td>\n",
       "      <td>-0.710312</td>\n",
       "      <td>-0.591997</td>\n",
       "      <td>0.836300</td>\n",
       "      <td>-0.720247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>23</td>\n",
       "      <td>logo_99</td>\n",
       "      <td>1.645128</td>\n",
       "      <td>-1.911424</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>0.850210</td>\n",
       "      <td>0.554424</td>\n",
       "      <td>1.578238</td>\n",
       "      <td>-0.722733</td>\n",
       "      <td>-0.704658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883759</td>\n",
       "      <td>-2.000007</td>\n",
       "      <td>-0.517095</td>\n",
       "      <td>2.213172</td>\n",
       "      <td>0.733567</td>\n",
       "      <td>-0.577074</td>\n",
       "      <td>-0.710312</td>\n",
       "      <td>-0.591997</td>\n",
       "      <td>0.836300</td>\n",
       "      <td>-0.720247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     animation_id filename         0         1         2         3         4  \\\n",
       "0               0   logo_0  0.763518 -0.982797 -0.446681  1.089468 -0.070563   \n",
       "1               1   logo_0  0.851117 -1.775123  0.649689 -0.688600  0.216071   \n",
       "2               3   logo_0  0.291136 -0.928242  0.265542 -0.261439 -0.386160   \n",
       "3               4   logo_0  0.504446 -0.543099  0.915062  1.293575 -0.849605   \n",
       "4               5   logo_0 -0.641569 -0.657125 -0.105109 -0.031630 -0.572032   \n",
       "..            ...      ...       ...       ...       ...       ...       ...   \n",
       "902            21  logo_99  0.729620 -1.035586  0.390709  1.910684 -0.489203   \n",
       "903            22  logo_99  1.147938 -0.799806  0.664411  1.610482 -0.612273   \n",
       "904            22  logo_99  1.147938 -0.799806  0.664411  1.610482 -0.612273   \n",
       "905            23  logo_99  1.645128 -1.911424  0.806118  0.850210  0.554424   \n",
       "906            23  logo_99  1.645128 -1.911424  0.806118  0.850210  0.554424   \n",
       "\n",
       "            5         6         7  ...       246       247       248  \\\n",
       "0    0.710206 -0.491675 -1.631172  ...  0.339061  0.022934  0.195161   \n",
       "1    0.135211 -1.748761 -1.347670  ... -1.616431 -1.572003  0.242460   \n",
       "2    1.256256 -0.414706 -1.206105  ... -0.446020 -1.369758  0.356421   \n",
       "3    1.120387 -0.637641 -1.337280  ...  0.162753  0.206993 -0.201259   \n",
       "4    0.912017 -0.569627 -1.573482  ... -1.079276  0.285482  1.532865   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "902  2.197111  0.424709 -0.389426  ...  1.130544 -1.892641 -0.690288   \n",
       "903  1.194499  0.076532 -0.662109  ...  0.415811 -1.569571 -0.424470   \n",
       "904  1.194499  0.076532 -0.662109  ...  0.415811 -1.569571 -0.424470   \n",
       "905  1.578238 -0.722733 -0.704658  ...  0.883759 -2.000007 -0.517095   \n",
       "906  1.578238 -0.722733 -0.704658  ...  0.883759 -2.000007 -0.517095   \n",
       "\n",
       "          249       250       251       252       253       254       255  \n",
       "0   -0.046488 -0.492103 -0.605836 -1.282879  0.613195  0.297194 -0.172312  \n",
       "1    0.430259  0.079752 -1.039526 -0.696104  0.090277 -0.228757  0.144372  \n",
       "2    1.456656  0.468766 -1.077724 -0.548627 -0.300660  0.632805 -0.136473  \n",
       "3   -1.087391 -0.597388 -0.992079 -0.851486 -0.225463 -0.549269  0.088637  \n",
       "4   -0.375210 -0.249130 -0.551393 -1.024246  0.623726 -1.073305  0.166613  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "902  1.371062  0.718980 -0.827454 -0.557172  0.235162  0.523978 -0.592003  \n",
       "903  0.518902  0.160598 -1.283986 -0.463894  0.319661  0.785325 -0.294870  \n",
       "904  0.518902  0.160598 -1.283986 -0.463894  0.319661  0.785325 -0.294870  \n",
       "905  2.213172  0.733567 -0.577074 -0.710312 -0.591997  0.836300 -0.720247  \n",
       "906  2.213172  0.733567 -0.577074 -0.710312 -0.591997  0.836300 -0.720247  \n",
       "\n",
       "[907 rows x 258 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('AnimateSVG/src')\n",
    "from AnimateSVG.src.pipeline import *\n",
    "\n",
    "for i, row in svg_animations.iterrows():\n",
    "            try:\n",
    "                self._insert_animation(row['animation_id'], row['animation_vector'], filename_suffix=row['model'])\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {row['filename']}\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsvg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
